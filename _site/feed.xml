<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>筱筱汀的碎碎念</title>
    <description>欢迎聆听我的碎碎念😯</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 16 Mar 2018 19:51:43 +0800</pubDate>
    <lastBuildDate>Fri, 16 Mar 2018 19:51:43 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>面试问题总结</title>
        <description>&lt;h3 id=&quot;腾讯-2018-03-16&quot;&gt;腾讯 2018-03-16&lt;/h3&gt;
&lt;p&gt;听完段博士的中期答辩，回到实验室就接到一面电话，还好没回宿舍睡午觉哪…&lt;/p&gt;

&lt;p&gt;总体来说，我感觉自己对很多问题的理解都太浅了，稍微有点深入我就die了，还是得把每个问题扣细了看哪~&lt;/p&gt;

&lt;p&gt;然后虽然我投的是安全岗，但是一些编程相关的基础知识还是得看的。&lt;/p&gt;

&lt;p&gt;1.学过哪些跟安全相关的课程，印象最深的是什么课程，课程里面印象最深的是什么？&lt;/p&gt;

&lt;p&gt;我答了计算机网络，怕其他课程会踩坑，然后讲了DNS的解析过程，DNS劫持、DNS污染。
然后问了DNS劫持和污染不都是劫持吗，怎么去劫持？（我可能是答错了，不仔细看原理的后果很严重&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DNS劫持：&lt;code class=&quot;highlighter-rouge&quot;&gt;劫持了DNS服务器&lt;/code&gt;，通过某些手段取得某域名的解析记录控制权限，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP。解决:使用国外免费公用的DNS服务器，如8.8.8.8&lt;/li&gt;
  &lt;li&gt;DNS污染：让一般用户由于得到虚假目标主机IP而不能与其通信的方法，是一种DNS缓存投毒攻击，一旦发现与关键词相匹配的请求则立即伪装成目标域名的解析服务器给查询者返回虚假结果，直接在&lt;code class=&quot;highlighter-rouge&quot;&gt;协议上&lt;/code&gt;对用户的DNS请求进行干扰。解决:使用VPN&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.XSS是在&lt;code class=&quot;highlighter-rouge&quot;&gt;前端&lt;/code&gt;执行的，虽然有存储型XSS，但是还是在前端被X啊。会产生哪些影响：cookie劫持、后台增删改文章、钓鱼（利用xss构造出一个登录框，骗取用户账户密码）、xss蠕虫（利用xss漏洞进行传播）、修改网页代码（必须存在存储型xss漏洞，并且将结果返回到页面上）、利用网站重定向、获取用户信息（如浏览器信息，IP地址等）。&lt;/p&gt;

&lt;p&gt;3.CSRF的过程，会读数据吗？CSRF可以读数据，如2007年的Gmail CSRF漏洞，邮箱的Filter中会新创建一条规则，将所有带附件的邮件都转发到攻击者的邮箱中。&lt;/p&gt;

&lt;p&gt;token除了可以放在post包里面，还可以放在那里？用户的Session中，或者浏览器的cookie中。&lt;/p&gt;

&lt;p&gt;4.堡垒机是干什么的？（自己给自己挖的坑吧）
    运维堡垒主机是种具备强大防御功能和安全审计功能的服务器。基于跳板机理念，作为内外网络的个安全审计监测点，以达到把所有网站安全问题集中到某台服务器上解决，从而省时省力。同时运维堡垒主机还具备了，对运维人员的远程登录进行集中管理的功能作用。&lt;/p&gt;

&lt;p&gt;5.python的多线程、&lt;a href=&quot;http://blog.csdn.net/you_are_my_dream/article/details/56316826&quot;&gt;多进程&lt;/a&gt;,可能我还是需要把我辣鸡的小爬虫做成多线程的看看，回答起来才更有底气啊。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;背景：
    &lt;ul&gt;
      &lt;li&gt;GIL(Global Interpreter Lock):全局解释器锁&lt;/li&gt;
      &lt;li&gt;每个CPU在同一时间只能执行一个线程&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;多线程执行方式：
    &lt;ul&gt;
      &lt;li&gt;获取GIL&lt;/li&gt;
      &lt;li&gt;执行代码知道sleep或者是python虚拟机将其挂起&lt;/li&gt;
      &lt;li&gt;释放GIL&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;在Python2.x里，GIL的释放逻辑是当前线程遇见IO操作或者ticks计数达到100，而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源&lt;/li&gt;
  &lt;li&gt;是否多线程无用？
    &lt;ul&gt;
      &lt;li&gt;CPU密集型代码（循环、计数等），由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对&lt;code class=&quot;highlighter-rouge&quot;&gt;CPU密集型代码并不友好!!!!!!!!&lt;/code&gt;。&lt;/li&gt;
      &lt;li&gt;IO密集型代码（文件处理、爬虫等），多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对&lt;code class=&quot;highlighter-rouge&quot;&gt;IO密集型代码比较友好&lt;/code&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;多核多线程比单核多线程更差，原因是单核下多线程，每次释放GIL，唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，这样会造成线程颠簸(thrashing)，导致效率更低&lt;/li&gt;
  &lt;li&gt;python下想要充分利用多核CPU，就用多进程,每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，所以在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;6.&lt;a href=&quot;http://tech.ifeng.com/a/20180305/44895634_0.shtml&quot;&gt;DrDDoS&lt;/a&gt;为什么能放大5w倍：
Memcached的key-value功能。前文提到key-value的作用是决定存储容量的大小，正常情况下key-value的值通常不超过几千字节。当Memcached被攻击者利用作为反射器时，key-value的值经过修改可以达到100万字节以上。&lt;/p&gt;

&lt;p&gt;http://www.freebuf.com/vuls/164864.html&lt;/p&gt;

&lt;p&gt;7.C++ 为什么能继承（这个我再想想，可能我是把问题听错了）&lt;/p&gt;

&lt;p&gt;8.windows防御机制，哪个是第一个出现的？ASLR、DEP、GS&lt;/p&gt;

&lt;p&gt;9.Java反序列化，这个我要去具体分析几个poc了，要不然说起来真是没底气啊&lt;/p&gt;

&lt;p&gt;10.平时会看书吗？我说了在看兜哥的《web安全深度学习实战》，问我具体的章节问题，里面的demo我都还没试啊，懒惰如我…&lt;/p&gt;

&lt;p&gt;11.做过渗透测试吗：准备做一些 &lt;a href=&quot;hackthebox.eu&quot;&gt;hackbox&lt;/a&gt;上面的题目弥补无渗透经验的缺陷T.T&lt;/p&gt;
</description>
        <pubDate>Fri, 16 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6/</guid>
        
        <category>sec</category>
        
        
      </item>
    
      <item>
        <title>Word2Vec以及tf实现</title>
        <description>&lt;h3 id=&quot;引言&quot;&gt;引言？&lt;/h3&gt;

&lt;p&gt;大部分内容摘自《TensorFlow实战》（黄文坚），算是读书笔记，也会在网上搜集一些相关的文章进行补充。
我觉得这本书很nice呀，虽然没有对具体的神经网络进行详细的讲解，但是很通俗易懂，偏实战。
也会有看了神经网络的详解然后雨里雾里，再在这边看了总结的豁然开朗之感。&lt;/p&gt;

&lt;h3 id=&quot;one-hot-encoder&quot;&gt;One-Hot Encoder&lt;/h3&gt;

&lt;p&gt;最早的词向量表示方法为One-Hot Encoder，将字词转成离散的单独的符号：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;杭州 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0]
上海 [0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0]
宁波 [0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0]
北京 [0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;杭州、上海、宁波、北京各对应一个向量，向量中只有一个值为1，其余都为0。
使用One-Hot Encoder有一个问题，即对特征的编码是随机的，没有考虑到字词之间的关系。如北京、上海应该聚集到一起，华盛顿、纽约聚集在一起。并且效率低、计算麻烦。&lt;/p&gt;

&lt;h3 id=&quot;什么是word2vec&quot;&gt;什么是Word2Vec&lt;/h3&gt;

&lt;p&gt;循环神经网络是在NLP领域最常使用的神经网络，而Word2Vec则是将语言中的字词转化为计算机可以理解的稠密向量（Dense Vector），通过一个嵌入空间使得语义上相似的单词在该空间内距离很近。&lt;/p&gt;

&lt;p&gt;Word2Vec分为：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CBOW（Continuous Bag of Words）:从原始语句（例如：中国的首都是____）推测目标字词（例如：北京）

Skip-Gram:从目标字词推测出原始语句，在大型语料库中表现更好
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;负采样&lt;/code&gt;：在Word2Vec的CBOW模型中，只训练一个二分类模型，区分真实的目标词汇和编造的噪声词汇（Negative Sampling）。只需要计算随机选择的k个词汇而并非全部。在实际中，使用Noise-Contrastive Estimation（NCE）Loss，在tf中对应为&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.nce_loss()&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;模型拆解&quot;&gt;模型拆解&lt;/h3&gt;

&lt;p&gt;Word2Vec模型其实就是简单化的神经网络：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//1.jpg&quot; height=&quot;500&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图片来源:&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27234078&quot;&gt;理解 Word2Vec 之 Skip-Gram 模型&lt;/a&gt;,作者写的超级详细，可以去读读。&lt;/p&gt;

&lt;p&gt;输入是One-Hot Vector。
如果想要用300个特征来表示一个单词，则隐藏层的维度为300，且Hidden Layer没有激活函数。
Output Layer维度跟Input Layer的维度一样，用的是Softmax回归，输出概率分布。&lt;/p&gt;

&lt;p&gt;将从输入层到隐含层的那些权重，作为每一个词汇表中的词的向量。&lt;/p&gt;

&lt;p&gt;因为One-Hot Vector十分稀疏，消耗大量的计算资源。为了进行高效计算，只要选择选择矩阵中对应的向量中维度值为1的索引行：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//4.jpg&quot; height=&quot;150&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边向量中取值为1的对应维度为3（下标从0开始），那么计算结果就是矩阵的第3行（下标从0开始）—— [10, 12, 19]，这样模型中的隐层权重矩阵便成了一个”查找表“（lookup table）&lt;/p&gt;

&lt;p&gt;详细拆解参考&lt;a href=&quot;http://www.sohu.com/a/128794834_211120&quot;&gt;如果看了此文还不懂 Word2Vec，那是我太笨&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CBOW&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将一个词所在的上下文中的词作为输入，而那个词本身作为输出，也就是说，看到一个上下文，希望大概能猜出这个词和它的意思。通过在一个大的语料库训练，得到一个从输入层到隐含层的权重模型。如下图所示，第l个词的上下文词是i，j，k，那么i，j，k作为输入，它们所在的词汇表中的位置的值置为1。然后，输出是l，把它所在的词汇表中的位置的值置为1。训练完成后，就得到了每个词到隐含层的每个维度的权重，就是每个词的向量。例如第i个词的词向量为&lt;code class=&quot;highlighter-rouge&quot;&gt;(Wi,1 Wi,2...Wi,m)&lt;/code&gt;,m为向量的维度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//2.jpeg&quot; height=&quot;500&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Skip-gram&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将一个词所在的上下文中的词作为输出，而那个词本身作为输入，也就是说，给出一个词，希望预测可能出现的上下文的词。通过在一个大的语料库训练，得到一个从输入层到隐含层的权重模型。如下图所示，第l个词的上下文词是i，j，k，那么i，j，k作为输出，它们所在的词汇表中的位置的值置为1。然后，输入是l，把它所在的词汇表中的位置的值置为1。训练完成后，就得到了每个词到隐含层的每个维度的权重，就是每个词的向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//3.jpeg&quot; height=&quot;500&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tf实现word2vec&quot;&gt;tf实现Word2Vec&lt;/h3&gt;

&lt;p&gt;使用Skip-Gram模式的Word2Vec，以“the quick brown fox jumped over the lazy dog”为例，训练样本为(quick,the)，(quick,brown),(brown,quick),(brown,fox)等。训练时，希望模型可以从目标词汇quick推测出语境the，同时也需要制造随机的词汇作为负样本（噪声）。使用SGD（随机梯度下降算法）来更新模型中Word Embedding的参数，让概率分布的损失函数(NCE Loss)尽可能小。这样每个单词的Embedded Vector就会随着训练过程不断调整，直到处于一个最合适语料的空间位置。&lt;/p&gt;

&lt;p&gt;基本每一句都有注释啦，可以结合原书来看此段代码😳&lt;/p&gt;

&lt;p&gt;啊啊啊，我手工巧了一遍代码，才发现代码居然是tf上的&lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py&quot;&gt;demo&lt;/a&gt;…&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# -*- coding: UTF-8 -*-&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;zipfile&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# ---------------------------  数据预处理---------------------------&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'http://mattmahoney.net/dc/'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   从‘http://mattmahoney.net/dc’下载文本文件，里面约有17005207个用空格分隔好的英文句子。&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maybe_download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;statinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statinfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expected_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Found and verified'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statinfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'Failed to verify'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'. Can you get to it with a browser?'&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maybe_download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text8.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31344016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   filename = &quot;text8.zip&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   解压文件，并使用`tf.compat.as_str`将数据转化成单词列表。&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;namelist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Data size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   创建vocabulary词汇表,选取前50000频数的单词，其余单词认定为Unknown，编号为0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'UNK'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---------------------------------&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   collections.Counter统计单词列表中单词的频数&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   most_common 取top 50000频数的单词作为vocabulary&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   count = [(单词1,词频1),(单词2,词频2),...]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most_common&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   存入dic中&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  

    &lt;span class=&quot;c&quot;&gt;#   遍历单词列表，如果出现在dictionary中，则转化为编号。不在则为0。&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;unk_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;unk_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unk_count&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   字典的反转形式，可用编号查询出对应的单词&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   删除原始单词列表，节约内存&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   打印最高频出现的词汇及数量，[['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Most common words (+UNK)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   打印data前10个单词&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Sample data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   ---------------------------生成Word2Vec的训练样本---------------------------&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   使用Skip-Gram模式，将原始数据：&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   “the quick brown fox jumped over the lazy dog”转化为：&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   (quick,the)，(quick,brown),(brown,quick),(brown,fox)等。&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#  生成训练用的batch数据&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   skip_window 单词最远可以联系的距离&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   num_skips 对每个单词生成多少样本&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;#   定义为全局变量，因为会反复调用此函数&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   batch_size 必须为num_skips的整数倍，确保每个batch包含一个词汇对应的所有样本&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   ndarray对象是用于存放同类型元素的多维数组&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   某个单词创建样本时会使用到的单词数量,包括单词本身和它前后的单词&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;span&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   双向队列，使用append方法添加变量时，只会保留最后插入span个变量&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deque&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;c&quot;&gt;#   从序号data_index开始，把span个单词顺序读入buffer作为初始值&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# // 为整数除法&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;#   buffer中第skip_window个变量为目标单词&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;targets_to_avoid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;#   生成样本时需要避免的单词列表&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets_to_avoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;targets_to_avoid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   简单测试功能&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   训练数据&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 单词转为稠密向量的维度，一般是50~1000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 单词间最远可以联系的距离 &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 每个目标单词提取的样本数&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   验证数据，随机抽取一些频数最高的单词，看向量空间上跟它们最近的单词是否相关性比较高&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 抽取的验证单词数&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 验证单词只从频数最高的100个单词中抽取&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_examples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_sampled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 训练时用来做负样本的噪声单词的数量&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   ---------------------------定义Skip-Gram模型的网络结构---------------------------&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   将随机产生的valid_examples转换为constant&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;valid_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/cpu:0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   tf.random_uniform随机生成所有单词的词向量embeddings,单词表大小为50000，向量维度为128&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   tf.nn.embedding_lookup 查找输入train_inputs对应的向量&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   使用NCE Loss作为训练的优化目标&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nce_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;truncated_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nce_biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   loss的计算方式&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nce_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nce_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nce_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;num_sampled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_sampled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;#   定义优化器为SGD，lr为1.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   计算嵌入向量embeddings的L2范数norm&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   规范化&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   tf.nn.embedding_lookup 查询验证单词的嵌入向量&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;valid_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   计算验证单词的嵌入向量与词汇表中所有单词的相似性&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;similarity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   初始化所有模型参数&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   最大的迭代次数&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100001&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Initialized&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   生成一个batch的inputs和labels数据&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_val&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# 2000此循环，计算一下平均loss并显示出来&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Average loss at step &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

        &lt;span class=&quot;c&quot;&gt;# 每10000次循环，计算一次验证单词与全部单词的相似度，并将最相似的8个单词展示出来&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;valid_word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Nearest to &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_word&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;close_word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;c&quot;&gt;#close_word = reverse_dictionary.get(nearest[k])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s ,&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;final_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   ---------------------------可视化---------------------------&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# low_dim_embs 是降维到2维的单词的空间向量，在图表中展示每个单词的位置&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;plot_with_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'tsne.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;More labels than embeddings&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 显示散点图（单词的位置）&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# plt.annotate为单词本身&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;annotate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;     
                     &lt;span class=&quot;n&quot;&gt;xy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;xytext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;textcoords&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'offset points'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;ha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'right'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;va&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bottom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;#   保存图片到本地&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 降维,将原始的128维嵌入向量降到2维，展示词频最高的100个单词&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.manifold&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perplexity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pca&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_only&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_only&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_only&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_with_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Sat, 10 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/Word2Vec/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/Word2Vec/</guid>
        
        <category>AI</category>
        
        
      </item>
    
      <item>
        <title>安全岗面试相关问题--网络相关</title>
        <description>&lt;h3 id=&quot;怎么又要开始准备面试了&quot;&gt;怎么又要开始准备面试了&lt;/h3&gt;
&lt;p&gt;下面总结的内容都比较简略，可能是摘抄了《白帽子》，可能是网上搜集的资料，或者直接给出了别人总结的很好的文章供以后查看，因为每个点展开来将都可以写好几篇文章（嗯，为自己偷懒找借口&lt;/p&gt;

&lt;h3 id=&quot;osi七层模型&quot;&gt;OSI七层模型&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/网络//osi.png&quot; height=&quot;400&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tcp&quot;&gt;TCP&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/li_ning_/article/details/52117463&quot;&gt;TCP与UDP的区别&lt;/a&gt;
&lt;img src=&quot;/images/posts/2018/03/网络//tcpudp.png&quot; height=&quot;250&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/xulu_258/article/details/51146489&quot;&gt;三次握手&lt;/a&gt;
&lt;img src=&quot;/images/posts/2018/03/网络//三次.jpeg&quot; height=&quot;400&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;四次握手
&lt;img src=&quot;/images/posts/2018/03/网络//四次.jpeg&quot; height=&quot;500&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为何连接的时候是三次，关闭的时候是四次
  因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dns解析&quot;&gt;DNS解析&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/网络//dns.jpg&quot; height=&quot;500&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/23042131/answer/66571369&quot;&gt;知乎&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在浏览器中输入www  . qq  .com 域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。&lt;/li&gt;
  &lt;li&gt;如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。&lt;/li&gt;
  &lt;li&gt;如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的&lt;code class=&quot;highlighter-rouge&quot;&gt;首选DNS服务器&lt;/code&gt;，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。&lt;/li&gt;
  &lt;li&gt;如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。&lt;/li&gt;
  &lt;li&gt;如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(http://qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找http://qq.com域服务器，重复上面的动作，进行查询，直至找到www  . qq  .com主机。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DNS在进行&lt;a href=&quot;https://www.cnblogs.com/lca1826/p/6599269.html&quot;&gt;区域传输&lt;/a&gt;的时候用TCP，其他时候用UDP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.williamlong.info/archives/3356.html&quot;&gt;DNS劫持与污染&lt;/a&gt;：
    &lt;ul&gt;
      &lt;li&gt;DNS劫持就是指用户访问一个被标记的地址时，DNS服务器故意将此地址指向一个错误的IP地址的行为。范例，网通、电信、铁通的某些用户有时候会发现自己打算访问一个地址，却被转向了各种推送广告等网站，这就是DNS劫持。&lt;/li&gt;
      &lt;li&gt;DNS污染，指的是用户访问一个地址，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。范例，访问Youtube、Facebook之类网站等出现的状况。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;https相关&quot;&gt;HTTPS相关&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/kobejayandy/article/details/52433660&quot;&gt;https的原理&lt;/a&gt;
  &lt;img src=&quot;/images/posts/2018/03/网络//https.jpg&quot; height=&quot;500&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/RIcZNMUWd8P7Quel4vU_Yg&quot;&gt;HTTPS 协议降级攻击原理&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;由客户端（如浏览器）发送第一个数据包 ClientHello，这个数据包中保存着客户端支持的&lt;code class=&quot;highlighter-rouge&quot;&gt;加密协议版本&lt;/code&gt;。&lt;/li&gt;
      &lt;li&gt;服务器收到这个ClientHello数据包，查看里面客户端支持的加密协议版本，然后匹配服务器自己支持的加密协议版本，从而确认双方应该用的加密协议版本。&lt;/li&gt;
      &lt;li&gt;服务器发送ServerHello数据包给客户端，告诉客户端要使用什么加密协议版本。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;如果客户端声称自己只支持某个旧版本有漏洞的加密协议，且服务器支持此协议，则攻击有可能发生。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https流量如何检测:这个问题是不是类似于用&lt;a href=&quot;http://blog.csdn.net/zyw_anquan/article/details/47904495&quot;&gt;burp&lt;/a&gt;抓包的问题啊，下载CA证书，导入到浏览器，并设置为信任。（待补充吧&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;拒绝服务攻击&quot;&gt;拒绝服务攻击&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/26828198&quot;&gt;浅谈DDoS攻击与防御&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;网络层DDoS攻击
    &lt;ul&gt;
      &lt;li&gt;SYN flood:三次握手的缺陷；措施：SYN cookie/SYN Proxy、safereset算法等&lt;/li&gt;
      &lt;li&gt;UDP flood：UDP是一种无连接的协议，伪造大量的源IP去发送UDP包。但UDP包双向流量基本对等，也会消耗自身资源&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ICMP flood：不断发送不正常的ICMP包（内容很大，占带宽）。目前很多服务器禁ping(防火墙可以屏蔽)。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;防御：
        &lt;ul&gt;
          &lt;li&gt;网络架构优化，采用负载均衡&lt;/li&gt;
          &lt;li&gt;添加抗DDoS设备，流量清洗&lt;/li&gt;
          &lt;li&gt;限制单IP请求频率&lt;/li&gt;
          &lt;li&gt;防火墙等保护设置禁止icmp包等&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;应用层DDoS
    &lt;ul&gt;
      &lt;li&gt;CC攻击：
        &lt;ul&gt;
          &lt;li&gt;对一些消耗资源较大的应用页面不断发起正常的请求，如数据库查询；&lt;/li&gt;
          &lt;li&gt;篡改流量大的A网站页面，加入&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;iframe src = &quot;target&quot;&amp;gt;&lt;/code&gt;，则每当有人访问A，则也会对目标站发起get请求。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Slowloris攻击：以极低的速度往服务器发送http请求（完整的http头是的结尾是&lt;code class=&quot;highlighter-rouge&quot;&gt;\r\n\r\n&lt;/code&gt;）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;HTTP POST DoS:发送http post包时，指定一个非常大的content-length值，再以很低的速度发包&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Server Limit DoS:这是由于cookie导致的dos攻击，当然其原理还是基于webserver的特性。apache默认最大的http包头长度为8192字节，如果超出此长度，则会返回4xx错误。如果我们利用存储型xss漏洞，将一个超长的cookie写入客户端页面，则用户再访问此页面后，由于请求头加载了恶意的超长cookie，导致其不能访问该站的页面（除非清空cookie）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ReDoS:代码写得有缺陷，导致使用正则时，会出现大量占用资源的情况，导致服务不可用&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;措施：
        &lt;ul&gt;
          &lt;li&gt;使用频率高的数据放在memcache中（最近有新闻报道&lt;a href=&quot;http://www.freebuf.com/company-information/163963.html&quot;&gt;Memcached&lt;/a&gt;的安全漏洞导致github被大规模DDoS）&lt;/li&gt;
          &lt;li&gt;网络架构优化，充分利用好CDN和镜像站点的分流作用&lt;/li&gt;
          &lt;li&gt;限制请求频率&lt;/li&gt;
          &lt;li&gt;验证码（验证过程：对比用户提交的明文和服务器端Session里存放的验证码明文是否一致）&lt;/li&gt;
          &lt;li&gt;判断UA（不可靠）&lt;/li&gt;
          &lt;li&gt;让客户端解析一段JS（不可靠）（类似于区块链里面的Hashcash）&lt;/li&gt;
          &lt;li&gt;Apache的配置文件里，调小timeout、keepalivetimeout，增加maxclients，合理配置中间件&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 09 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>安全岗面试相关问题--web常见漏洞原理与防御</title>
        <description>&lt;h3 id=&quot;怎么又要开始准备面试了&quot;&gt;怎么又要开始准备面试了&lt;/h3&gt;
&lt;p&gt;下面总结的内容都比较简略，可能是摘抄了《白帽子》，可能是网上搜集的资料，或者直接给出了别人总结的很好的文章供以后查看，因为每个点展开来将都可以写好几篇文章（嗯，为自己偷懒找借口&lt;/p&gt;

&lt;h3 id=&quot;xss&quot;&gt;XSS&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;常见类型：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;反射型XSS：把用户输入的数据“反射”给浏览器，即需要用户点击某链接&lt;/li&gt;
      &lt;li&gt;存储型XSS：把用户输入的数据存储在服务器&lt;/li&gt;
      &lt;li&gt;DOM Based XSS：也属于反射型XSS，修改页面的DOM节点形成XSS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其他类型的XSS：&lt;a href=&quot;http://www.fooying.com/the-art-of-xss-1-introduction/&quot;&gt;跨站的艺术-XSS入门与介绍&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;mXSS:突变型XSS，原本无害，而由于一些特殊原因，如反编码等，导致Payload发生变异，导致的XSS。如：旧版QQ客户端中的链接预览。&lt;/li&gt;
      &lt;li&gt;UXSS:利用浏览器或者浏览器扩展漏洞来制造产生XSS的条件并执行代码的一种攻击类型,可以理解为Bypass同源策略。&lt;a href=&quot;http://www.fooying.com/uxss/&quot;&gt;通用跨站脚本攻击(UXSS)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Flash XSS:来源于 getURL/navigateToURL（访问跳转）、ExternalInterface.call（调用js函数）&lt;/li&gt;
      &lt;li&gt;UTF-7 XSS:低版本IE中未指定meta编码或指定编码为UTF-7&lt;/li&gt;
      &lt;li&gt;MHTML XSS:低版本IE中&lt;/li&gt;
      &lt;li&gt;CSS XSS:&lt;code class=&quot;highlighter-rouge&quot;&gt;body {width:expression(alert(1));: red;}&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;VBScript XSS:&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;input type =&quot;button&quot; onClick=&quot;VBScript:Document.Write 'hello mr. Fooying' MsgBox 'xss'&quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;注入点：
  GET参数、POST参数、UA、Referer…一切可以提交的输入点&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;危害：&lt;a href=&quot;https://thief.one/2017/05/31/1/&quot;&gt;浅谈跨站脚本攻击与防御&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;cookie劫持&lt;/li&gt;
      &lt;li&gt;后台增删改文章&lt;/li&gt;
      &lt;li&gt;钓鱼，利用xss构造出一个登录框，骗取用户账户密码。&lt;/li&gt;
      &lt;li&gt;xss蠕虫（利用xss漏洞进行传播）&lt;/li&gt;
      &lt;li&gt;修改网页代码:必须存在存储型xss漏洞，并且将结果返回到页面上
  （javascript加载外部的代码文件可以是任意扩展名（无扩展名也可以））&lt;/li&gt;
      &lt;li&gt;利用网站重定向&lt;/li&gt;
      &lt;li&gt;获取用户信息（如浏览器信息，IP地址等）:调用java Applet的接口获取客户端本地IP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;防御：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;在Cookie中设置&lt;code class=&quot;highlighter-rouge&quot;&gt;HttpOnly&lt;/code&gt;标识,禁止页面的js访问带有httponly属性的cookie&lt;/li&gt;
      &lt;li&gt;XSS Filter：过滤用户输入的危险字符，设置黑白名单&lt;/li&gt;
      &lt;li&gt;输出检查：编码和转义，常用编码：html编码、url编码、js编码、16进制、base64等，使得浏览器无法解析执行js代码&lt;/li&gt;
      &lt;li&gt;针对不同位置的输出，使用不同的处理方式&lt;/li&gt;
      &lt;li&gt;处理富文本:限制用户能使用的标签，限制为只能使用a、div等安全的标签&lt;/li&gt;
      &lt;li&gt;header中使用content-Sencurity-Policy字段，规定请求js的域名白名单（CSP策略）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;绕过：
    &lt;ul&gt;
      &lt;li&gt;转换大小写&lt;/li&gt;
      &lt;li&gt;大小写混写&lt;/li&gt;
      &lt;li&gt;双引号改单引号&lt;/li&gt;
      &lt;li&gt;引号改为/&lt;/li&gt;
      &lt;li&gt;用全角字符&lt;/li&gt;
      &lt;li&gt;使用javascript伪协议&lt;/li&gt;
      &lt;li&gt;使用回车、空格等特殊字符&lt;/li&gt;
      &lt;li&gt;在css的style中使用/**/注释符&lt;/li&gt;
      &lt;li&gt;使用字符编码&lt;/li&gt;
      &lt;li&gt;利用事件触发xss&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;a href=&quot;https://security.yirendai.com/news/share/26&quot;&gt;浅谈XSS—字符编码和浏览器解析原理&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;常用payload：&lt;a href=&quot;https://www.t00ls.net/thread-42640-1-1.html&quot;&gt;t00ls&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sql-injection&quot;&gt;SQL Injection:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;原理：数据与代码未分离&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;数据库相关：
    &lt;ul&gt;
      &lt;li&gt;mysql 5.0版本以后提供了information.schema数据库：
  &lt;img src=&quot;/images/posts/2018/03/web/sql/1.png&quot; height=&quot;200&quot; width=&quot;300&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;查看该数据库中的表：schemata、tables、columns需要重点关注
  &lt;img src=&quot;/images/posts/2018/03/web/sql/2.png&quot; height=&quot;800&quot; width=&quot;500&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;schemata：所有数据库的基本信息，包括数据库名，编码类型，路径等。schema_name列即为数据库名。
  &lt;img src=&quot;/images/posts/2018/03/web/sql/3.png&quot; height=&quot;150&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
          &lt;li&gt;tables: 储存mysql中的表信息，table_schema是库名信息，table_nama是表名（图太大了，不截了）&lt;/li&gt;
          &lt;li&gt;columns：提供了表中的列信息，columns_name字段对应的字段名&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;系统函数：
        &lt;ul&gt;
          &lt;li&gt;user() ：当前使用者的用户名&lt;/li&gt;
          &lt;li&gt;database()：当前数据库名&lt;/li&gt;
          &lt;li&gt;version()：数据库版本&lt;/li&gt;
          &lt;li&gt;datadir：读取数据库的绝对路径&lt;/li&gt;
          &lt;li&gt;@@vasedir：mysql安装路径&lt;/li&gt;
          &lt;li&gt;@@version_compile_os：操作系统&lt;/li&gt;
          &lt;li&gt;concat()：连接一个或者多个字符串&lt;/li&gt;
          &lt;li&gt;group_concat()：连接一个组的所有字符串，并以逗号分隔每一条数据&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.51cto.com/wt7315/1828167&quot;&gt;分类&lt;/a&gt;：
    &lt;ul&gt;
      &lt;li&gt;基于联合查询
        &lt;ul&gt;
          &lt;li&gt;UNION:合并两个或多个SELECT语句的结果集，并消去表中重复的行。UNION 内部的 SELECT 语句必须拥有相同数量的列，列也必须拥有相似的数据类型。&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,version(),database()&lt;/code&gt;可以爆出当前使用的版本和数据库名&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,schema_name from information_schema.schemata limit 1,1 %23爆出数据库名，依次使用limit2，1往下爆库名&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(schema_name) from information_schema.schemata %23&lt;/code&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;假设有flag库：
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(table_name) from information_schema.tables where schema_name=’flag’&lt;/code&gt; 爆出flag库下的所有的表，假设其中有flagtable表&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(column_name) from information_schema.columns where table_name =’flagtale’&lt;/code&gt;爆出flagtable下的所有字段，假设有name和password字段&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(name,password) from flag.flagtable&lt;/code&gt; 爆出flag下的flagtable表的name和password的内容&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.51cto.com/wt7315/1891458&quot;&gt;基于错误回显&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;用到的函数：
            &lt;ul&gt;
              &lt;li&gt;count():统计元祖的个数
   &lt;img src=&quot;/images/posts/2018/03/web/sql/4.png&quot; height=&quot;100&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;rand():0~1的随机数
   &lt;img src=&quot;/images/posts/2018/03/web/sql/5.png&quot; height=&quot;100&quot; width=&quot;250&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;floor():向下取整,select floor(rand()*2);的结果为0或者1
   &lt;img src=&quot;/images/posts/2018/03/web/sql/6.png&quot; height=&quot;200&quot; width=&quot;250&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;group_concat():将数据进行拼接
   &lt;img src=&quot;/images/posts/2018/03/web/sql/7.png&quot; height=&quot;100&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;整合语句：&lt;code class=&quot;highlighter-rouge&quot;&gt;select count(*),concat(0x3a,0x3a,database(),0x3a,floor(rand()*2))name from information_schema.tables group by name;&lt;/code&gt;
 &lt;img src=&quot;/images/posts/2018/03/web/sql/8.png&quot; height=&quot;200&quot; width=&quot;800&quot; /&gt;
            &lt;ul&gt;
              &lt;li&gt;生成随机数并取整，然后用分号将不同的数据拼接，并取别名name，最后将结果以name进行分组并进行统计，能看到统计出的两个不同的取值，0和1。&lt;/li&gt;
              &lt;li&gt;多重复几次就会报错
 &lt;img src=&quot;/images/posts/2018/03/web/sql/9.png&quot; height=&quot;30&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;公式：&lt;code class=&quot;highlighter-rouge&quot;&gt;username=admin' and (select 1 from (select count(*), concat(floor(rand(0)*2),0x23,(你想获取的数据的sql语句))x from information_schema.tables group by x )a) and '1' = '1&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;基于盲注
        &lt;ul&gt;
          &lt;li&gt;时间盲注:
            &lt;ul&gt;
              &lt;li&gt;加入特定的时间函数，通过查看是web页面返回的时间差来判断注入的语句是否正确&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and if(ascii(substr((select schema_name from information_schema.schemata limit 1,1),1,1))&amp;gt;100,1,sleep(3))%23&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;布尔型的盲注: &lt;code class=&quot;highlighter-rouge&quot;&gt;and ascii(substr(@@datadir,1,1)）&amp;gt;69 %23&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;二次注入:分为语句插入和语句执行&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.91ri.org/8611.html&quot;&gt;宽字节注入&lt;/a&gt;:  （字符集好方啊，我得专门总结一篇啊😂
        &lt;ul&gt;
          &lt;li&gt;mysql的转义函数：&lt;code class=&quot;highlighter-rouge&quot;&gt;addslashes&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql_real_escape_string&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql_escape_string&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;的ascii码为&lt;code class=&quot;highlighter-rouge&quot;&gt;0x5c&lt;/code&gt;,会结合成新的字符&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.anquanke.com/post/id/85936&quot;&gt;其他&lt;/a&gt;：
        &lt;ul&gt;
          &lt;li&gt;读文件：SELECT LOAD_FILE(‘/etc/passwd’);&lt;/li&gt;
          &lt;li&gt;写文件：
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT '&amp;lt;? system($_GET['c']); ?&amp;gt;' INTO OUTFILE/DUMPFILE '/var/www/shell.php';&lt;/code&gt;&lt;/li&gt;
              &lt;li&gt;into dumpfile 能导出一个完整能执行的2进制文件,函数不对任何列或行进行终止，也不执行任何转义处理&lt;/li&gt;
              &lt;li&gt;在UDF提权的场景是需要上传二进制文件等等用dumpfile&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;带外通道：利用其他协议或者渠道从服务器提取数据. 它可能是HTTP（S）请求，DNS解析服务，SMB服务，Mail服务等.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.zerokeeper.com/web-security/sqlmap-usage-summary.html&quot;&gt;sqlmap的使用&lt;/a&gt;，最基础的使用方法如下：
    &lt;ul&gt;
      &lt;li&gt;sqlmap -u “xxx”&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” –current-db&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” -D DB名 –tables&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” -D DB名 -T 表名 –columns&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” -D DB名 -T 表名 -C 字段名 –dump&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.lengbaikai.net/?p=110&quot;&gt;tamper绕WAF&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;其他注入：
    &lt;ul&gt;
      &lt;li&gt;XML注入&lt;/li&gt;
      &lt;li&gt;代码注入&lt;/li&gt;
      &lt;li&gt;CRLF注入：\r\n,0x0d,0x0a&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;防御：
    &lt;ul&gt;
      &lt;li&gt;waf&lt;/li&gt;
      &lt;li&gt;使用预编译语句，绑定变量&lt;/li&gt;
      &lt;li&gt;检查数据类型，例如限制输入数据只能为int&lt;/li&gt;
      &lt;li&gt;使用安全函数,encodeForSQL()&lt;/li&gt;
      &lt;li&gt;最小权限原则，避免直接使用root&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;csrf&quot;&gt;CSRF:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;原理：通过伪装来自受信任用户的请求来利用受信任的网站,例如：用户登录某账户，浏览器获得cookie；攻击者诱使用户访问某构造好的恶意CSRF页面。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;防御：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;验证码&lt;/li&gt;
      &lt;li&gt;Referer Check（HTTPS跳转到HTTP不会发送Referer）&lt;/li&gt;
      &lt;li&gt;Anti CSRF Token&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ssrfserver-side-request-forgery&quot;&gt;SSRF（Server-Side Request Forgery）&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/s0ky1xd/p/5859049.html&quot;&gt;浅谈SSRF漏洞&lt;/a&gt;
&lt;a href=&quot;http://www.91ri.org/17111.html&quot;&gt;SSRF漏洞分析与利用&lt;/a&gt;
&lt;a href=&quot;https://joychou.org/web/phpssrf.html&quot;&gt;SSRF in PHP&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;原理：利用漏洞伪造服务器端发起请求，从而突破客户端获取不到数据限制，一般用来在外网探测或攻击内网服务&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可利用的伪协议：&lt;code class=&quot;highlighter-rouge&quot;&gt;dict file ftp ftps gopher http https imap imaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftp &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/web//ssrf.png&quot; height=&quot;400&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;防御：
    &lt;ul&gt;
      &lt;li&gt;过滤返回信息&lt;/li&gt;
      &lt;li&gt;限制请求端口为http常用的端口&lt;/li&gt;
      &lt;li&gt;内网IP黑名单&lt;/li&gt;
      &lt;li&gt;禁用不需要的协议&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;xxe&quot;&gt;XXE&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://thief.one/2017/06/20/1/&quot;&gt;浅谈XXE漏洞攻击与防御&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原理：应用程序解析XML输入时，没有禁止外部实体的加载，导致可加载恶意外部文件，造成文件读取、命令执行、内网端口扫描、攻击内网网站、发起dos攻击等危害。
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;!ENTITY 实体名称 SYSTEM &quot;URI&quot;&amp;gt;&lt;/code&gt;,支持file、http、https、ftp等&lt;/li&gt;
      &lt;li&gt;触发的点往往是可以上传xml文件的位置，没有对上传的xml文件进行过滤，导致可上传恶意xml文件&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;防御：
    &lt;ul&gt;
      &lt;li&gt;使用开发语言提供的禁用外部实体的方法&lt;/li&gt;
      &lt;li&gt;过滤用户提交的XML数据，过滤关键词：&amp;lt;!DOCTYPE和&amp;lt;!ENTITY，或者SYSTEM和PUBLIC。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_web%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E4%B8%8E%E9%98%B2%E5%BE%A1/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_web%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E4%B8%8E%E9%98%B2%E5%BE%A1/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>安全岗面试相关问题--同源策略与跨域</title>
        <description>&lt;h3 id=&quot;怎么又要开始准备面试了&quot;&gt;怎么又要开始准备面试了&lt;/h3&gt;
&lt;p&gt;上次准备面试还是15年大三的时候啊，真心是什么都不懂（虽然现在也是…会用wamp建个站就投了安全岗啊233…我真是哪里来的勇气…&lt;/p&gt;

&lt;p&gt;今天看到当年投阿里写的在线简历，真是惨不忍睹，估计当时HR看到了以为我是在搞笑吧🤣&lt;/p&gt;

&lt;p&gt;下面总结的内容都比较简略，可能是摘抄了《白帽子》，可能是网上搜集的资料，或者直接给出了别人总结的很好的文章供以后查看，因为每个点展开来将都可以写好几篇文章（嗯，为自己偷懒找借口&lt;/p&gt;

&lt;p&gt;然后，把CHYbeta大神的&lt;a href=&quot;https://github.com/CHYbeta/Web-Security-Learning&quot;&gt;Web-Security-Learning&lt;/a&gt;过一遍😳？&lt;/p&gt;

&lt;h3 id=&quot;什么是同源策略&quot;&gt;什么是同源策略&lt;/h3&gt;

&lt;p&gt;源就是&lt;code class=&quot;highlighter-rouge&quot;&gt;[主机，协议，端口名]&lt;/code&gt;的一个三元组。
（此外，cookie的同源策略是&lt;code class=&quot;highlighter-rouge&quot;&gt;[主机，端口名]&lt;/code&gt;，不包含协议，因此可以用http的cookie去覆盖https的cookie。）&lt;/p&gt;

&lt;p&gt;同源策略(Same Origin Policy, SOP)：限制了来自不同源的”document“或者脚本，对当前”document“读取或者设置某些属性。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script&amp;gt;、&amp;lt;img&amp;gt;、&amp;lt;iframe&amp;gt;、&amp;lt;link&amp;gt;&lt;/code&gt;等标签都可以跨域加载资源，而不受同源策略的限制，但是浏览器限制了JS的权限，使其不能读、写返回的资源。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;XMLHttpRequest&lt;/code&gt;不可以跨域加载资源，但是可以读写资源。如果可以跨域，则会导致一些敏感数据的泄漏，如CSRF Token。&lt;/p&gt;

&lt;p&gt;XHR需要根据&lt;code class=&quot;highlighter-rouge&quot;&gt;目标域&lt;/code&gt;返回的HTTP头来授权是否允许跨域访问，因为&lt;code class=&quot;highlighter-rouge&quot;&gt;JS无法控制HTTP头&lt;/code&gt;（这点非常重要啊啊啊啊啊啊，👻👽💀🤖👏👏👏）。XSS在没有其他辅助的情况下也无法控制HTTP头啊啊啊啊。&lt;/p&gt;

&lt;p&gt;除了DOM、Cookie、XHR受到同源策略的限制，第三方插件如Flash（crossdomain.xml、MIME）、Java、Applet等都有自己的同源策略。&lt;/p&gt;

&lt;p&gt;跨域的方式主要有：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CORS
CSP
JSONP
postMessage
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;cross-origin-resource-sharingcors&quot;&gt;Cross-origin Resource Sharing(CORS)&lt;/h3&gt;

&lt;p&gt;例如从&lt;code class=&quot;highlighter-rouge&quot;&gt;http://www.a.com/test.html&lt;/code&gt;发起对&lt;code class=&quot;highlighter-rouge&quot;&gt;http://www.b.com/test.php&lt;/code&gt;的请求，请求头中包含&lt;code class=&quot;highlighter-rouge&quot;&gt;origin:http://www.a.com&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;（origin header 可以用于防范CSRF，不像Refer那么容易被伪造或清空，此处的referer怎么改？？？？？😱😱😱😱😱😱😱😱😱😱😱）&lt;/p&gt;

&lt;p&gt;如果www.b.com返回的http Header中包含：&lt;code class=&quot;highlighter-rouge&quot;&gt;Access control allow origin:http://www.a.com&lt;/code&gt;,则表示这个跨域请求被通过。（下图是图糙理不糙啊啊啊&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/SOP/ACAO.png&quot; height=&quot;250&quot; width=&quot;450&quot; /&gt;&lt;/p&gt;

&lt;p&gt;还有很多其他的标准：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Access-Control-Allow-Origin
Access-Control-Allow-Methods
Access-Control-Allow-Headers
Access-Control-Max-Age
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;content-security-policycsp&quot;&gt;Content Security Policy(CSP)&lt;/h3&gt;

&lt;p&gt;由服务器返回一个HTTP头，并在其中描述页面该遵守的安全策略。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X-Content-Security-Policy:allow 'self' *.mydomain.com    // 浏览器将信任来自mydomain.com及其子域名下面的内容
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;CSP的实质为白名单，在浏览器层面做的防护，是和同源策略同一级别，除非浏览器本身出现漏洞，否则不可能从机制上绕过。
CSP只允许被认可的JS块、JS文件、CSS等解析，只允许向指定的域发起请求。&lt;/p&gt;

&lt;p&gt;CSP怎么能有这么多姿势…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://jaq.alibaba.com/community/art/show?spm=a313e.7916646.24000001.49.ZP8rXN&amp;amp;articleid=518&quot;&gt;Content Security Policy 入门教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://paper.seebug.org/423/&quot;&gt;前端防御从入门到弃坑–CSP变迁&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;jsonp只支持get请求&quot;&gt;JSONP(只支持get请求)&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;JSONP(JSON with Padding)&lt;/code&gt;是一个简单高效的跨域方式，可以简单理解为带callback的json。利用&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签没有跨域限制的“漏洞”（历史遗迹啊）来达到与第三方通讯的目的。
参考&lt;a href=&quot;https://www.zhihu.com/question/19966531/answer/13502030&quot;&gt;知乎&lt;/a&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;当需要通讯时，本站脚本创建一个&amp;lt;script&amp;gt;元素，地址指向第三方的API网址，形如:

    &amp;lt;script src=&quot;http://www.example.net/api?param1=1&amp;amp;param2=2&quot;&amp;gt;&amp;lt;/script&amp;gt;

并提供一个回调函数来接收数据（函数名可约定，或通过地址参数传递）。     

第三方产生的响应为json数据的包装（故称之为jsonp，即json padding），形如：     

    callback({&quot;name&quot;:&quot;hax&quot;,&quot;gender&quot;:&quot;Male&quot;})     

这样浏览器会调用callback函数，并传递解析后json对象作为参数。本站脚本可在callback函数里处理所传入的数据。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;JSONP是CSP的克星&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script src=&quot;/path/jsonp?callback=alert(document.domain)//&quot;&amp;gt; &amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;postmessage&quot;&gt;postMessage&lt;/h3&gt;

&lt;p&gt;postMessage允许每一个window（包括当前窗口、弹出窗口、iframe等）对象往其他的窗口发送文本消息，从而实现跨窗口的消息传递，不受同源策略限制。&lt;/p&gt;

&lt;h3 id=&quot;同源攻防&quot;&gt;同源攻防&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.anquanke.com/post/id/86078&quot;&gt;漫谈同源策略攻防&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对URI的解析：&lt;/p&gt;

    &lt;p&gt;在某些浏览器对URI的解释存在漏洞的时候，可以构造相应的攻击连绕过SOP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;设计缺陷绕过SOP：&lt;/p&gt;

    &lt;p&gt;在Java6，7中，如果两个域名解析到相同的IP，则会认为他们同源。假设我们有attacker.com和victim.com,两者都共享主机123.123.123.123。攻击者attacker.com可以在自己控制的域名下上传一个jar文件来访问victim.com的内容。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;访问本地文件的同源策略&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;frame src=&quot;/home/user/dir/2.html&quot;&amp;gt;&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;frame src=&quot;/home/user/2.html&quot;&amp;gt;&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;1.html与2.html视为同源&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特立独行的IE：&lt;/p&gt;

    &lt;p&gt;TrustZones（信任域）：当一个URI被加入到了IE的信任网站区域中时，浏览器会无视同源策略。&lt;/p&gt;

    &lt;p&gt;IE在考虑同源策略时不包括端口， 这意味着不同端口上的应用程序可以读取到比如用户的登陆账户密码/cookie等。&lt;/p&gt;

    &lt;p&gt;通过变更自身的源绕过同源策略：IE 6，7版中网页可以通过document.domain设置自身的来源为任意其他来源&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;防御&quot;&gt;防御&lt;/h3&gt;
&lt;p&gt;最好的防御方式则是设置CORS&lt;/p&gt;

&lt;p&gt;禁止跨域写，引入CSRF令牌，且必须正确的配置同源策略，否则令牌也会被读取。&lt;/p&gt;

&lt;p&gt;禁止跨域读，我们可以通过设置&lt;code class=&quot;highlighter-rouge&quot;&gt;X-Frame-Options&lt;/code&gt;头来禁止该页面被嵌入到恶意页面中&lt;/p&gt;

&lt;p&gt;禁止跨域嵌入，比如&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script data-original=&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;、 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;img data-original=x&amp;gt;&amp;lt;/img&amp;gt;&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;svg onload=&amp;gt;&lt;/code&gt;，各种字体加载等等。同时，使用CSRF令牌也可以有效避免被跨域嵌入。&lt;/p&gt;

</description>
        <pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E7%9B%B8%E5%85%B3/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E7%9B%B8%E5%85%B3/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>LSTM相关的一些问题</title>
        <description>&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;最近在看深度学习相关的东西，就把一些自己想了很久，网上的答案也不是很详细的东西记录下来，可能会有部分错误，会不断改进哒。&lt;/p&gt;

&lt;h3 id=&quot;rnn-与-lstm-相关基础&quot;&gt;RNN 与 LSTM 相关基础&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;网上看到的RNN的网络图如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM//RNN-shorttermdepdencies.png&quot; height=&quot;280&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是也可以将RNN的网络图画成如下的模式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM//LSTM3-SimpleRNN.png&quot; height=&quot;280&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;是不是很眼熟！对，LSTM只是在RNN的基础上进行了扩展，添加了很多gate来控制之前的记忆，以解决RNN可能引起的梯度弥散与梯度爆炸(这里可以参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25518711&quot;&gt;YJango的循环神经网络——实现LSTM&lt;/a&gt;)的问题。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;传统的LSTM的网络图看上去特别复杂:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM//LSTM3-chain.png&quot; height=&quot;280&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;小圆圈是point-wise的操作，比如向量加法、点乘等&lt;/li&gt;
      &lt;li&gt;小矩形代表一层可学习参数的神经网络（重点啊！！！！！！！！&lt;/li&gt;
      &lt;li&gt;上面的一条直线代表了LSTM的状态state，贯穿所有LSTM单元，gate控制对其添加或删除信息&lt;/li&gt;
      &lt;li&gt;gate只是为了控制每次输入多少、遗忘多少、输出多少信息。通过学习和训练，来调节这个gate的值，以达到最好的效果。类似于一个阀门控制水流的多少，具体阀门的松紧即gate的值，需要通过反复学习训练来得到。具体可以参考：
  &lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;Understanding LSTM Networks&lt;/a&gt;，
  &lt;a href=&quot;https://zhuanlan.zhihu.com/p/25518711&quot;&gt;YJango的循环神经网络——实现LSTM&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，很多LSTM想不清楚的问题，可以直接用RNN来类比啦🤗~&lt;/p&gt;

&lt;h3 id=&quot;lstm的输入与输出&quot;&gt;LSTM的输入与输出&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;首先还是看下RNN的输入与输出吧(摘自&lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;)：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/charseq.jpeg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;An example RNN with 4-dimensional input and output layers, and a hidden layer of 3 units (neurons). 
This diagram shows the activations in the forward pass when the RNN is fed the characters &quot;hell&quot; as input. 
The output layer contains confidences the RNN assigns for the next character (vocabulary is &quot;h,e,l,o&quot;); 
We want the green numbers to be high and red numbers to be low.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;将”hello”这个单词的每次字母进行One-Hot编码，每输入一个字母预测下一个输出的字母是什么。例如，输入h对应输出e，输入e对应输出l，而输入l则可能对应l或者o。此处对应4维的输入与输出层，一个有着三个神经元的隐藏层。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;batch_size&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;input_size&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;time_steps&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;num_units&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;layer_num&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;class_num&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;再看下这个知乎回答上的这个图,可能会更加清晰一些:
&lt;img src=&quot;/images/posts/2018/03/LSTM/知乎RNN图.jpg&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/41949741/answer/318771336&quot;&gt;作者：Scofield&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;所以，LSTM的输入与输出是怎样的呢？可以完全类比RNN的输入与输出。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/myLSTM.jpg&quot; height=&quot;600&quot; width=&quot;850&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这张图我手工画的，可能有不对的地方，主要参考了&lt;a href=&quot;https://jasdeep06.github.io/posts/Understanding-LSTM-in-Tensorflow-MNIST/&quot;&gt;Understanding LSTM in Tensorflow(MNIST dataset)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;困惑了我最久的是num_units到底是什么，然后&lt;a href=&quot;https://www.zhihu.com/question/41949741/answer/309529532&quot;&gt;知乎&lt;/a&gt;这个回答好详细！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/singleLSTMcell.png&quot; height=&quot;300&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图中四个黄色的框框就是传统的前馈神经网络，而num_units就是这个前馈神经网络里面的隐藏节点啊啊啊啊。&lt;/p&gt;

&lt;h3 id=&quot;关于张量tensor的一些疑惑&quot;&gt;关于张量(tensor)的一些疑惑&lt;/h3&gt;

&lt;p&gt;神经网络的处理单位均为&lt;code class=&quot;highlighter-rouge&quot;&gt;向量&lt;/code&gt;，所以&lt;code class=&quot;highlighter-rouge&quot;&gt;张量&lt;/code&gt;是什么？&lt;/p&gt;

&lt;p&gt;主要参考这篇文章&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25268020&quot;&gt;数学不行还学AI-第4话-图解张量&lt;/a&gt;,写的通俗易懂，我就不摘抄啦噜。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/tensor.jpg&quot; height=&quot;500&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;p&gt;常见的张量有：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3D = 时间序列   (time, frequency, channel)

4D = 图像      (sample_size, width, height, color_depth)

5D = 视频      (sample_size, frames, width, height, color_depth))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;总而言之，张量想要多少维就多少维，就看你的需求与设计啦。&lt;/p&gt;

&lt;h3 id=&quot;暂时就写这么多吧想到了再补充&quot;&gt;暂时就写这么多吧，想到了再补充&lt;/h3&gt;

</description>
        <pubDate>Thu, 01 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/LSTM%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/LSTM%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</guid>
        
        <category>AI</category>
        
        
      </item>
    
      <item>
        <title>杂七杂八的安全tips</title>
        <description>&lt;h3 id=&quot;xss-tips&quot;&gt;XSS TIPS&lt;/h3&gt;

&lt;p&gt;Ref:&lt;a href=&quot;https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Open%20redirect&quot;&gt;PayloadsAllTheThings&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;使用&lt;code class=&quot;highlighter-rouge&quot;&gt;CRLF&lt;/code&gt;:    (&lt;code class=&quot;highlighter-rouge&quot;&gt;CR&lt;/code&gt;:&lt;code class=&quot;highlighter-rouge&quot;&gt;\r&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;0x0d&lt;/code&gt;;&lt;code class=&quot;highlighter-rouge&quot;&gt;LF&lt;/code&gt;:&lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;0x0a&lt;/code&gt;)
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java%0d%0ascript%0d%0a:alert(0)
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;XSS from Open URL - If it’s in a JS variable
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;;alert(0);//
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;XSS from data:// wrapper
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://www.example.com/redirect.php?url=data:text/html;base64,PHNjcmlwdD5hbGVydCgiWFNTIik7PC9zY3JpcHQ+Cg==
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;XSS from javascript:// wrapper
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://www.example.com/redirect.php?url=javascript:prompt(1)
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 02 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/01/secTips/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/01/secTips/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>这人生首三个弱弱的CVE</title>
        <description>&lt;h3 id=&quot;cve-2017-17971&quot;&gt;&lt;a href=&quot;https://www.cvedetails.com/cve/CVE-2017-17971/&quot;&gt;CVE-2017-17971&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;一直觉得是大厂的通用型漏洞，非常高大上的那种。&lt;/p&gt;

&lt;p&gt;年末的前两天，狗科在推特上发现了一个做安全的小伙子，发了自己的第一个CVE截图。&lt;/p&gt;

&lt;p&gt;看了下漏洞详情，发现就是个在忘记密码处的很简单的XSS，几乎不用绕过。&lt;/p&gt;

&lt;p&gt;于是我也尝试在&lt;a href=&quot;https://www.cvedetails.com/&quot;&gt;CVE details&lt;/a&gt;网站上找一些已经有CVE编号的CRM。&lt;/p&gt;

&lt;p&gt;Dolibarr CRM ,出于尝试的心态在忘记密码处试了xss语句，报错提示是出现了注入的语句，并且有对应的文件名。&lt;/p&gt;

&lt;p&gt;下载了源码，发现只对部分xss语句进行的过滤，&lt;code class=&quot;highlighter-rouge&quot;&gt;onclick&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;onscroll&lt;/code&gt;并不在黑名单里，然后就是存储型XSS。&lt;/p&gt;

&lt;p&gt;第一次提交CVE，Discover我以为是填写个人或者组织(我想成了二分类问题，一定是最近机器学习看多了…)直接填上了individual…Reference我以为是参考文献…后来在github提交了issue，描述了漏洞详情。&lt;/p&gt;

&lt;h3 id=&quot;cve-2017-18004&quot;&gt;&lt;a href=&quot;https://www.cvedetails.com/cve/CVE-2017-18004/&quot;&gt;CVE-2017-18004&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;zurmo这个之前有过挺多个xss的cve，感觉已经把过滤做的很好了，也没报太大希望。&lt;/p&gt;

&lt;p&gt;吃午饭前开了burp扫描，睡完午觉回来发现扫出来xss了，但是只是回显在js代码里面，并没有执行。&lt;/p&gt;

&lt;p&gt;后来狗科帮我闭合了下，成功弹框。&lt;/p&gt;

&lt;h3 id=&quot;cve-2018-3814&quot;&gt;&lt;a href=&quot;https://www.cvedetails.com/cve/CVE-2018-3814/&quot;&gt;CVE-2018-3814&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;CraftCMS纯粹是我想看看有啥小众的CMS漏洞有CVE，发现可以试用Demo，就申请了看看。&lt;/p&gt;

&lt;p&gt;本着有上传就必有漏洞的精神，试了下改文件名后缀。&lt;/p&gt;

&lt;p&gt;一开始不行，后来无意中发现如果上传两张同样的图片的话，第二张同名的图片可以改成”.php”后缀。&lt;/p&gt;

&lt;p&gt;打开php文件，发现可以解析，但是里面的shell语句被GD库过滤没了。&lt;/p&gt;

&lt;p&gt;想来研一的时候做过一个CMSeasy getshell的漏洞复现，里面就有绕过GD库的说明。&lt;/p&gt;

&lt;p&gt;也怪自己当初没有搞得特别清楚，浪费了一点时间。再去仔细看别人的说明，发现得多试几张图片才行。&lt;/p&gt;

&lt;p&gt;成功出现&lt;code class=&quot;highlighter-rouge&quot;&gt;phpinfo&lt;/code&gt;的图片的时候，我的手都是抖的🤣，算是第一次自己挖出来一个中危漏洞吧&lt;/p&gt;
</description>
        <pubDate>Tue, 02 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/01/myfirstCVE/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/01/myfirstCVE/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>2018开年的碎碎念</title>
        <description>&lt;h3 id=&quot;关于此博客的闲置与启用&quot;&gt;关于此博客的闲置与启用&lt;/h3&gt;
&lt;p&gt;问我闲置这么久的原因 ? 还不是因为我懒🤣…并且觉得markdown的图片大小很难控制。&lt;/p&gt;

&lt;p&gt;再次启用是因为今天清理Gmail邮箱的时候，看到有个妹子在17年7月份的时候，给我发邮件请教博客搭建相关的问题。&lt;/p&gt;

&lt;p&gt;嘤嘤嘤，我的Gmail塞满了twitter的垃圾邮件，并且觉得没人联系我，也懒得check，好愧疚。&lt;/p&gt;

&lt;p&gt;另外元旦假期的时候挖到了三个CVE，两个XSS，一个图片上传。准备把一些挖洞详情写在这里吧，总觉得在CSDN还有博客园写这些不太好。&lt;/p&gt;

&lt;h3 id=&quot;2018年的一些展望&quot;&gt;2018年的一些展望&lt;/h3&gt;
&lt;p&gt;在深圳把毕设做完，五月份可以安心回北京找实习，想去3BAT😊&lt;/p&gt;

&lt;p&gt;希望以后可以从事&lt;code class=&quot;highlighter-rouge&quot;&gt;安全+AI&lt;/code&gt;相关的工作吧，毕竟自己入门了这么久安全，研一也选了机器学习相关课程，现在的毕设机缘巧合下做了深度学习。&lt;/p&gt;

&lt;p&gt;当然重中之重就是要多挖漏洞，感觉多看漏洞详情多去复现漏洞还是很有用的。&lt;/p&gt;

&lt;p&gt;还有就是跑步健身，去年的体检查出来不少不是很紧要的小病，还是得重视起来吧，早睡早起😋~&lt;/p&gt;

&lt;h3 id=&quot;知道图片怎么调整大小啦更新于20180303-&quot;&gt;知道图片怎么调整大小啦！（更新于2018.03.03 ）&lt;/h3&gt;

&lt;p&gt;我之前都是这么插入图片的，&lt;code class=&quot;highlighter-rouge&quot;&gt;![](/images/readme//index.png) &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/readme//index.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后酱紫插入图片就可以控制长宽啦，&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;img src=&quot;/images/readme//index.png&quot; height=&quot;400&quot; width=&quot;700&quot;&amp;gt; &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/readme//index.png&quot; height=&quot;400&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 02 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/01/2018Boom/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/01/2018Boom/</guid>
        
        <category>碎碎念</category>
        
        
      </item>
    
      <item>
        <title>unsigned int 与 signed int</title>
        <description>&lt;h3 id=&quot;unsigned-int&quot;&gt;unsigned int&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;unsigned int&lt;/code&gt; : 无符号数，0~2^n - 1。遇到负数，则以&lt;strong&gt;补码&lt;/strong&gt;形式存储。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(signed) int&lt;/code&gt; : 有符号数，-2^(n-1)~2^(n-1) - 1&lt;/p&gt;

&lt;h3 id=&quot;简单的循环问题&quot;&gt;简单的循环问题&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;signed&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;//有符号数
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;此处的i&amp;lt;0.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;//无符号数，此处将i初始化为负数，以补码形式存储，在计算机中是一个很大的数
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;此处的i&amp;gt;0.&lt;/p&gt;

&lt;h3 id=&quot;溢出问题&quot;&gt;溢出问题&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;cm&quot;&gt;/* Kernel memory region holding user-accessible data */&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define KSIZE 1024
&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kbuf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KSIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* Copy at most maxlen bytes from kernel region to user buffer */&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;copy_from_kernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_dest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* Byte count len is minimum of buffer size and maxlen */&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KSIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KSIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;memcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_dest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kbuf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;此处的&lt;strong&gt;len&lt;/strong&gt;选择 &lt;code class=&quot;highlighter-rouge&quot;&gt;KSIZE&lt;/code&gt;与&lt;code class=&quot;highlighter-rouge&quot;&gt;maxlen&lt;/code&gt;中长度较短的。&lt;/p&gt;

&lt;p&gt;但是如果此时&lt;code class=&quot;highlighter-rouge&quot;&gt;maxlen&lt;/code&gt;为&lt;strong&gt;负数&lt;/strong&gt;，以补码形式存储，即为一个很大的数。&lt;/p&gt;

&lt;p&gt;再结合&lt;code class=&quot;highlighter-rouge&quot;&gt;memcpy&lt;/code&gt;会造成缓冲区溢出。&lt;/p&gt;
</description>
        <pubDate>Thu, 28 Sep 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/09/unsigned/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/09/unsigned/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
  </channel>
</rss>
