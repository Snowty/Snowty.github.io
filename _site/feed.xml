<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>筱筱汀的碎碎念</title>
    <description>欢迎聆听我的碎碎念😯</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 02 Apr 2018 20:34:18 +0800</pubDate>
    <lastBuildDate>Mon, 02 Apr 2018 20:34:18 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>HTTP报文解析</title>
        <description>&lt;h3 id=&quot;详解&quot;&gt;详解&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u010256388/article/details/68491509&quot;&gt;HTTP请求行、请求头、请求体详解&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/04/HTTP报文//1.jpg&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;①&lt;a href=&quot;http://www.runoob.com/http/http-methods.html&quot;&gt;请求方法(HTTP 1.1中支持)&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/u010529455/article/details/42918639&quot;&gt;解析HTTP协议六种请求方法,get,head,put,delete,post有什么区别&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;get：提交的数据最多1024字节&lt;/li&gt;
      &lt;li&gt;head：只请求页面的首部&lt;/li&gt;
      &lt;li&gt;post:数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。&lt;/li&gt;
      &lt;li&gt;put：与post相似，但是会指定资源的存放位置&lt;/li&gt;
      &lt;li&gt;options：允许客户端查看服务器的性能,获取当前URL所支持的方法&lt;/li&gt;
      &lt;li&gt;delete：删除某一资源，返回的状态码（200：ok，202：Accepted，204：No Content）&lt;/li&gt;
      &lt;li&gt;trace：回显服务器收到的请求，主要用于测试或诊断&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.web-tinker.com/article/20055.html&quot;&gt;connect&lt;/a&gt;：动态切换为隧道的代理，把服务器作为跳板，让服务器代替用户去访问其它网页，之后把数据原原本本的返回给用户。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;②URL地址&lt;/p&gt;

&lt;p&gt;③协议名称及版本号&lt;/p&gt;

&lt;p&gt;④&lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_HTTP_header_fields&quot;&gt;HTTP报文头&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些标准报文头：
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Accept:text/plain&lt;/code&gt;:告诉服务器，客户端接受什么类型的相应,属性值可以为一个或者多个&lt;a href=&quot;https://en.wikipedia.org/wiki/Media_type&quot;&gt;MIME&lt;/a&gt;类型的值&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Accept-Charset: utf-8&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Accept-Encoding: gzip, deflate&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Accept-Language: en-US&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Access-Control-Request-Method: GET&lt;/code&gt;:&lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-origin_resource_sharing&quot;&gt;Cross-origin resource sharing&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Host&lt;/code&gt;:The domain name of the server&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Connection: keep-alive&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Origin: http://www.example-social-network.com&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Content-Type: application/x-www-form-urlencoded&lt;/code&gt;:Media type of the body of the request(post and put)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cookie&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Referer&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Cache-Control: no-cache&lt;/code&gt;:让服务端将对应请求返回的响应内容不要在客户端缓存&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/12.0&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Content-Length: 348&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;X-Forwarded-For: client1, proxy1, proxy2&lt;/code&gt;:&lt;a href=&quot;http://blog.csdn.net/caiqiiqi/article/details/72852083&quot;&gt;绕过服务器IP地址过滤&lt;/a&gt;,tcp层伪造源IP比较困难可以在http层进行伪造&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;X-Frame-Options: deny&lt;/code&gt;:&lt;a href=&quot;http://blog.csdn.net/wangnan537/article/details/76599962&quot;&gt;防止网页被Frame&lt;/a&gt;,点劫持防御。&lt;code class=&quot;highlighter-rouge&quot;&gt;deny&lt;/code&gt;表示页面不能被嵌入到任何iframe或frame中。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;⑤报文体：将一个页面表单中的组件值通过param1=value1&amp;amp;param2=value2的键值对形式编码成一个格式化串，它承载多个请求参数的数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/04/HTTP报文//2.jpg&quot; height=&quot;200&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;状态码&quot;&gt;&lt;a href=&quot;https://www.jianshu.com/p/49ebc4a78474&quot;&gt;状态码&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;HTTP的响应状态码由3位数字构成，根据第一位数字的值可以把HTTP响应分为5类：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;1xx：代表响应已经被服务器接受，需要继续处理&lt;/li&gt;
  &lt;li&gt;2xx：这一类型的状态码，表示该HTTP请求已经被服务器成功接受和理解。&lt;/li&gt;
  &lt;li&gt;3xx：重定向标识。表示客户端需要采取进一步操作才能完成请求，重定向地址会在本次响应报文的消息报头中给出，其字段名为Location。&lt;/li&gt;
  &lt;li&gt;4xx：客户端错误。这类状态码表示发送请求的客户端发生了错误，妨碍了服务器的请求处理。&lt;/li&gt;
  &lt;li&gt;5xx：服务器错误。其表示服务器在处理请求的过程中有错误或者异常状态发生，也可能是服务器当前的硬件资源无法完成对客户端的请求处理。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;常见状态码：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;200 OK：客户端请求成功。&lt;/li&gt;
  &lt;li&gt;400 Bad Request：客户端请求有语法错误，不能被服务器所理解。&lt;/li&gt;
  &lt;li&gt;401 Unauthorized：请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用。&lt;/li&gt;
  &lt;li&gt;403 Forbidden：服务器收到请求，但是拒绝提供服务。&lt;/li&gt;
  &lt;li&gt;404 Not Found：请求资源不存在，举个例子：输入了错误的URL。&lt;/li&gt;
  &lt;li&gt;500 Internal Server Error：服务器发生不可预期的错误。&lt;/li&gt;
  &lt;li&gt;503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常，举个例子：HTTP/1.1 200 OK（CRLF）。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 02 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/04/HTTP%E8%AF%B7%E6%B1%82%E5%A4%B4/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/04/HTTP%E8%AF%B7%E6%B1%82%E5%A4%B4/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>Hack the box 的一些write up</title>
        <description>&lt;h3 id=&quot;celestial&quot;&gt;&lt;a href=&quot;https://www.hackthebox.eu/home/machines/profile/130&quot;&gt;Celestial&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nmap -sC -sV 10.10.10.85&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;发现3000端口开了node.js服务&lt;/li&gt;
  &lt;li&gt;查找到node.js反序列化RCE，&lt;a href=&quot;https://opsecx.com/index.php/2017/02/08/exploiting-node-js-deserialization-bug-for-remote-code-execution/&quot;&gt;Exploiting Node.js deserialization bug for Remote Code Execution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;反弹shell后查看到&lt;code class=&quot;highlighter-rouge&quot;&gt;/home/sun/Documents/user.txt&lt;/code&gt;里面是用户flag，同目录下有个&lt;code class=&quot;highlighter-rouge&quot;&gt;script.py&lt;/code&gt;
&lt;img src=&quot;/images/posts/2018/03/HTB/85/1.png&quot; height=&quot;80&quot; width=&quot;280&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;查看当前进程里面有没有python脚本，发现root正在运行这个脚本，猜测可能是个crontab定时任务
&lt;img src=&quot;/images/posts/2018/03/HTB/85/2.png&quot; height=&quot;200&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;将&lt;code class=&quot;highlighter-rouge&quot;&gt;script.py&lt;/code&gt;的内容改为反弹shell语句，成功反弹root shell&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;crontab -l&lt;/code&gt;查看定时任务：
&lt;img src=&quot;/images/posts/2018/03/HTB/85/3.png&quot; height=&quot;100&quot; width=&quot;800&quot; /&gt;
[参考文章]&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/xiaoxiaoleo/p/8379977.html&quot;&gt;Linux提权思路&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.waitalone.cn/linux-shell-rebound-under-way.html&quot;&gt;Linux下反弹shell方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 22 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/HTB/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/HTB/</guid>
        
        <category>sec</category>
        
        
      </item>
    
      <item>
        <title>文字框选相关问题(R-CNN,SPPNET,Fast R-CNN,Faster R-CNN,CTPN,YOLO )</title>
        <description>&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;
&lt;p&gt;搜集了别人总结的文章，加上自己做的小笔记，供复习查看用。&lt;/p&gt;

&lt;h3 id=&quot;数据集&quot;&gt;数据集&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tzutalin/labelImg&quot;&gt;图片框选与标注工具&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/框选//1.jpg&quot; height=&quot;350&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ImageNet ILSVC 2012:    标定每张图片中物体的类别。一千万图像，1000类&lt;/p&gt;

    &lt;p&gt;PASCAL VOC 2007:        标定每张图片中，物体的类别和位置，一万图像，20类
 （VOC物体检测任务：如果某数据集包含了20个物体类别，则还需要加上背景类，总共21类）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;r-cnn&quot;&gt;R-CNN&lt;/h3&gt;

&lt;p&gt;这个博主写的文章，真的是很清晰啊，把所有不清楚的名词都解释好了~&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/23006190?refer=xiaoleimlnote&quot;&gt;RCNN-将CNN引入目标检测的开山之作&lt;/a&gt;
&lt;a href=&quot;http://blog.csdn.net/WoPawn/article/details/52133338&quot;&gt;R-CNN论文详解&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/框选//RCNN.png&quot; height=&quot;200&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.  候选区域生成： 采用Selective Search的方法在一张图像生成1K~2K个候选区域(Region Proposal)
    + 此阶段搜索出来的候选框，大小各不相同，需要缩放(crop/warp)成227*227的固定尺寸

2.  特征提取： 将每个Region Proposal输入到CNN，将CNN的fc7层的输出作为特征
    + 网络设计：使用Alexnet，5层卷积2个全连接，f7的神经元个数都是4096，最后每个输入候选框图片都能得到一个4096维的特征向量
    + 网络有监督预训练阶段（ImageNet）：标签较少，所以使用Alexnet直接初始化参数，SGD,lr = 0.001
    + fine-tuning阶段（PASCAL VOC）：将上面预训练的最后一层替换成N+1个输出（N类再加一个背景，此处为21）。SGD，lr = 0.001，batch_size = 128(32个正样本，96个负样本)
    + 正负样本：一张图有2000个候选框，而人工标注只有正确的BBX。所以候选框与BBX的重叠区域IoU大于0.5，则视为正样本

3.  类别判断： 特征送入每一类的SVM分类器，判别是否属于该类 
    + SVM训练阶段：
        + 检测窗口只包含部分物体，IoU的阈值为0.3，则小于0.3时为负样本。
        + 一旦CNN f7层特征被提取出来，则为每个物体类训练一个svm分类器。
        + 当我们用CNN提取2000个候选框，可以得到2000*4096这样的特征向量矩阵
        + 然后只需要把这样的一个矩阵与svm权值矩阵4096*N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)。

        + 位置精修：目标检测问题的衡量标准是重叠面积：许多看似准确的检测结果，往往因为候选框不够准确，重叠面积很小。故需要一个位置精修步骤

    + 测试阶段：
        + 使用selective search的方法在测试图片上提取2000个region propasals ，将每个region proposals归一化到227x227，然后再CNN中正向传播，将最后一层得到的特征提取出来。
        + 然后对于每一个类别，使用为这一类训练的SVM分类器对提取的特征向量进行打分，得到测试图片中对于所有region proposals的对于这一类的分数，
        + 再使用贪心的非极大值抑制（NMS）去除相交的多余的框。再对这些框进行canny边缘检测，就可以得到bounding-box(then B-BoxRegression)。

4.  位置精修： 使用回归器精细修正候选框位置 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;相关的知识点：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ selective search：将图像分割成小区域（1~2K个），按照规则（纹理、颜色等）合并相邻的两个区域，直到整个图像合并成一个区域位置。输出所有曾经存在过的区域，所谓候选区域
+ 重叠度（IOU）：两个BBX的重叠度，即矩形框A、B的重叠面积占A、B并集的面积比例
+ 非极大值抑制（NMS）：一张图片中找出N个可能是同一物体的矩形框，需要判别哪些框是没有用的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分`交叉`的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/框选//IOU.png&quot; height=&quot;250&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sppnet&quot;&gt;SPPNet&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24774302?refer=xiaoleimlnote&quot;&gt;SPPNet-引入空间金字塔池化改进RCNN&lt;/a&gt;
&lt;img src=&quot;/images/posts/2018/03/CTPN//4.jpg&quot; height=&quot;280&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;总体流程依旧是： Selective Search得到候选区域-&amp;gt;CNN提取RoI特征-&amp;gt;类别判断-&amp;gt;位置精修&lt;/li&gt;
  &lt;li&gt;但是在faeture map上提取ROI特征，只需要在整张图像上做一次卷积，提高了效率
&lt;img src=&quot;/images/posts/2018/03/CTPN//5.jpg&quot; height=&quot;80&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;原始图像的RoI如何映射到特征图：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24780433&quot;&gt;原始图片中的ROI如何映射到到feature map?&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;感受野(receptive field,某一层&lt;code class=&quot;highlighter-rouge&quot;&gt;输出结果&lt;/code&gt;中一个元素所对应的&lt;code class=&quot;highlighter-rouge&quot;&gt;输入层&lt;/code&gt;的区域大小)的计算：
        &lt;ul&gt;
          &lt;li&gt;卷基层的输出：
  &lt;code class=&quot;highlighter-rouge&quot;&gt;output= ( input - kernel size + 2*padding ) / stride + 1&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;卷积层的输入：
  &lt;code class=&quot;highlighter-rouge&quot;&gt;input = （output  - 1）* stride - 2*padding + kernel size&lt;/code&gt;
  &lt;img src=&quot;/images/posts/2018/03/CTPN//6.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;上面只是给出了 前一层在后一层的感受野，如何计算最后一层在原始图片上的感受野呢？ 从后向前级联一下就可以了（先计算最后一层到倒数第二层的感受野，再计算倒数第二层到倒数第三层的感受野，依次从后往前推导就可以了）&lt;/li&gt;
      &lt;li&gt;SPP-net 是把原始ROI的左上角和右下角 映射到 feature map上的两个对应点。 有了feature map上的两队角点就确定了 对应的 feature map 区域(下图中橙色)。 
  &lt;img src=&quot;/images/posts/2018/03/CTPN//7.jpg&quot; height=&quot;300&quot; width=&quot;500&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RoI在特征图上对应的特征区域的维度不满足全连接层的输入要求
    &lt;ul&gt;
      &lt;li&gt;空间金字塔池化：假设原图输入是224x224，对于conv5出来后的输出是13x13x256的，可以理解成有256个这样的filter，每个filter对应一张13x13的reponse map。如果像下图那样将reponse map分成1x1(金字塔底座)，2x2(金字塔中间)，4x4（金字塔顶座）三张子图，分别做&lt;code class=&quot;highlighter-rouge&quot;&gt;max pooling&lt;/code&gt;后，出来的特征就是(16+4+1)x256 维度。如果原图的输入不是224x224，出来的特征依然是(16+4+1)x256维度。这样就实现了不管图像尺寸如何 池化n 的输出永远是 （16+4+1）x256 维度。 
&lt;img src=&quot;/images/posts/2018/03/CTPN//3.jpg&quot; height=&quot;280&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fast-r-cnn&quot;&gt;Fast R-CNN&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24780395?refer=xiaoleimlnote&quot;&gt;Fast R-CNN&lt;/a&gt;
&lt;img src=&quot;/images/posts/2018/03/CTPN//8.jpg&quot; height=&quot;600&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;joint training （SVM分类，bbox回归 联合起来在CNN阶段训练）把最后一层的Softmax换成两个，一个是对区域的分类Softmax（包括背景），另一个是对bounding box的微调。这个网络有两个输入，一个是整张图片，另一个是候选proposals算法产生的可能proposals的坐标。&lt;/li&gt;
  &lt;li&gt;提出了一个RoI层，算是SPP的变种，SPP是pooling成多个固定尺度，RoI只pooling到单个固定的尺度 （论文通过实验得到的结论是多尺度学习能提高一点点mAP，不过计算量成倍的增加，故单尺度训练的效果更好。）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;faster-r-cnn&quot;&gt;Faster R-CNN&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24916624?refer=xiaoleimlnote&quot;&gt;Faster R-CNN&lt;/a&gt;
&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31426458&quot;&gt;一文读懂Faster R-CNN&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/CTPN//10.jpg&quot; height=&quot;300&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将特征抽取(feature extraction)，proposal提取，bounding box regression(rect refine)，classification都整合在了一个网络中
&lt;img src=&quot;/images/posts/2018/03/CTPN//9.jpg&quot; height=&quot;600&quot; width=&quot;800&quot; /&gt;
分为以下四步：&lt;/li&gt;
  &lt;li&gt;Conv layers。作为一种CNN网络目标检测方法，Faster R-CNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN层和全连接层。&lt;/li&gt;
  &lt;li&gt;Region Proposal Networks。RPN网络用于生成region proposals。该层通过softmax判断anchors属于foreground或者background，再利用bounding box regression修正anchors获得精确的proposals。&lt;/li&gt;
  &lt;li&gt;Roi Pooling。该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。&lt;/li&gt;
  &lt;li&gt;Classification。利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。
&lt;img src=&quot;/images/posts/2018/03/CTPN/11.jpg&quot; height=&quot;400&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;yolo&quot;&gt;YOLO&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24916786&quot;&gt;图解YOLO&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;ctpn&quot;&gt;CTPN&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://slade-ruan.me/2017/10/22/text-detection-ctpn/&quot;&gt;论文阅读与实现–CTPN&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;对比与小结&quot;&gt;对比与小结&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/35887527/answer/73048322&quot;&gt;知乎&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;mapmean-average-precision&quot;&gt;mAP(mean average precision)&lt;/h3&gt;

</description>
        <pubDate>Wed, 21 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E6%96%87%E5%AD%97%E6%A1%86%E9%80%89/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E6%96%87%E5%AD%97%E6%A1%86%E9%80%89/</guid>
        
        <category>AI</category>
        
        
      </item>
    
      <item>
        <title>Java反序列化</title>
        <description>&lt;h3 id=&quot;定义&quot;&gt;定义&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.vulbox.com/knowledge/detail/?id=11&quot;&gt;深入理解JAVA反序列化漏洞&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;序列化  ：把Java对象转换为字节序列的过程便于保存在内存、文件、数据库中，ObjectOutputStream类的writeObject()方法可以实现序列化。&lt;/li&gt;
  &lt;li&gt;反序列化：是指把字节序列恢复为Java对象的过程，ObjectInputStream类的readObject()方法用于反序列化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/java//definition.png&quot; height=&quot;150&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;序列化与反序列化是让Java对象脱离Java运行环境的一种手段，可以有效的实现多平台之间的通信、对象持久化存储。主要应用在以下场景：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;HTTP：多平台之间的通信，管理等

RMI：远程方法调用(Remote Method Invocation),让在某个java虚拟机上的对象像调用本地对象一样调用另一个java虚拟机中的对象上的方法。RMI的传输100%基于反序列化,默认端口是1099。

JMX：Java Management Extensions,让程序有被管理的功能，中间件软件WebLogic的管理页面就是基于JMX开发的，而JBoss则整个系统都基于JMX构架。 ​

JDNI(Java Naming and Directory Interface):提供了查找和访问各种命名和目录服务的通用、统一的接口,支持的对象有DNS、LDAP、 CORBA 对象服务、RMI 等。简单的来说就是RMI注册的服务可以让 JNDI 应用程序来访问，调用。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/java//rmi.png&quot; height=&quot;500&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;漏洞历史&quot;&gt;漏洞历史&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;15年的Apache Commons Collections 反序列化远程命令执行漏洞，其当初影响范围包括：WebSphere、JBoss、Jenkins、WebLogic 和 OpenNMSd等。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2016年Spring RMI反序列化漏洞今年比较出名的：Jackson，FastJson&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;漏洞成因&quot;&gt;漏洞成因&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;POP(property-oriented programming): 控制对象属性然后用它们去影响代码的运行流程。POP gadget就像是高级的ROP，POP组件是在文件中写入数据。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;反序列化的exp并不会直接发送代码让服务器去执行，只是发送&lt;code class=&quot;highlighter-rouge&quot;&gt;服务器已知的类的属性&lt;/code&gt;，然后去操纵那些已经存在的代码以处理这些恶意属性。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;入口点&quot;&gt;入口点&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;序列化对象以&lt;code class=&quot;highlighter-rouge&quot;&gt;ac ed&lt;/code&gt;开始，是magic number。接下来是&lt;code class=&quot;highlighter-rouge&quot;&gt;00 05&lt;/code&gt;，为版本号。接下来应该是0x70到0x7E之间的数，用于描述内容元素的类型，详情见&lt;a href=&quot;https://docs.oracle.com/javase/7/docs/platform/serialization/spec/protocol.html&quot;&gt;Object Serialization Stream Protocol&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;很多IDS靠&lt;code class=&quot;highlighter-rouge&quot;&gt;0xAC ED 00 05&lt;/code&gt;为特征码来判断序列化数据流，但是这几个字节仅出现在最初的序列化传输流里面。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;最显著的特征是在数据流里面会有java的类名，如&lt;code class=&quot;highlighter-rouge&quot;&gt;java.rmi.dgc.Lease&lt;/code&gt;，有的形式可能是&lt;code class=&quot;highlighter-rouge&quot;&gt;Ljava/rmi/dgc/VMID;’&lt;/code&gt;。除了类名，还有一些常见的字符串，如&lt;code class=&quot;highlighter-rouge&quot;&gt;sr&lt;/code&gt;可能会代表一个对象（TC_OBJECT）,紧跟着对应的类描述（TC_CLASSDESC）。&lt;code class=&quot;highlighter-rouge&quot;&gt;xp&lt;/code&gt;代表类注释的结束（TC_ENDBLOCKDATA），并且此类没有super class（TC_NULL）。（不太懂，我得再想想）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/java//Serialization-oi.png&quot; height=&quot;200&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;序列化对象读取工具：&lt;a href=&quot;https://github.com/NickstaDB/SerializationDumper&quot;&gt;SerializationDumper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pop-gadgets&quot;&gt;POP Gadgets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/frohoff/ysoserial/&quot;&gt;ysoserial&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://jackson.thuraisamy.me/runtime-exec-payloads.html&quot;&gt;java.lang.Runtime.exec() Payload Workarounds&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;防御&quot;&gt;防御&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;如何发现反序列化漏洞&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;从流量中发现序列化的痕迹，关键字：ac ed 00 05，rO0AB&lt;/li&gt;
      &lt;li&gt;Java RMI 的传输 100% 基于反序列化，Java RMI 的默认端口是1099端口&lt;/li&gt;
      &lt;li&gt;从源码入手，可以被序列化的类一定实现了Serializable接口&lt;/li&gt;
      &lt;li&gt;观察反序列化时的readObject()方法是否重写，重写中是否有设计不合理，可以被利用之处&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;防范&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;String obj2=(String)ois.readObject();&lt;/code&gt;这种方法并不能奏效，应为强制转换为&lt;code class=&quot;highlighter-rouge&quot;&gt;string&lt;/code&gt;之前readObject()函数就已经运行完毕&lt;/li&gt;
      &lt;li&gt;类白名单校验：在 ObjectInputStream 中 resolveClass 里只是进行了 class 是否能被 load ，自定义 ObjectInputStream , 重载 resolveClass 的方法，对 className 进行白名单校验&lt;/li&gt;
      &lt;li&gt;禁止 JVM 执行外部命令 Runtime.exec&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 17 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/Java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/Java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</guid>
        
        <category>sec</category>
        
        
      </item>
    
      <item>
        <title>面试问题总结</title>
        <description>&lt;h3 id=&quot;腾讯-2018-03-16&quot;&gt;腾讯 2018-03-16&lt;/h3&gt;
&lt;p&gt;听完段博士的中期答辩，回到实验室就接到一面电话，还好没回宿舍睡午觉哪…&lt;/p&gt;

&lt;p&gt;总体来说，我感觉自己对很多问题的理解都太浅了，稍微有点深入我就die了，还是得把每个问题扣细了看哪~&lt;/p&gt;

&lt;p&gt;然后虽然我投的是安全岗，但是一些编程相关的基础知识还是得看的。&lt;/p&gt;

&lt;p&gt;1.学过哪些跟安全相关的课程，印象最深的是什么课程，课程里面印象最深的是什么？&lt;/p&gt;

&lt;p&gt;我答了计算机网络，怕其他课程会踩坑，然后讲了DNS的解析过程，DNS劫持、DNS污染。
然后问了DNS劫持和污染不都是劫持吗，怎么去劫持？（我可能是答错了，不仔细看原理的后果很严重&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DNS劫持：&lt;code class=&quot;highlighter-rouge&quot;&gt;劫持了DNS服务器&lt;/code&gt;，通过某些手段取得某域名的解析记录控制权限，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP。解决:使用国外免费公用的DNS服务器，如8.8.8.8&lt;/li&gt;
  &lt;li&gt;DNS污染：让一般用户由于得到虚假目标主机IP而不能与其通信的方法，是一种DNS缓存投毒攻击，一旦发现与关键词相匹配的请求则立即伪装成目标域名的解析服务器给查询者返回虚假结果，直接在&lt;code class=&quot;highlighter-rouge&quot;&gt;协议上&lt;/code&gt;对用户的DNS请求进行干扰。解决:使用VPN&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.XSS是在&lt;code class=&quot;highlighter-rouge&quot;&gt;前端&lt;/code&gt;执行的，虽然有存储型XSS，但是还是在前端被X啊。会产生哪些影响：cookie劫持、后台增删改文章、钓鱼（利用xss构造出一个登录框，骗取用户账户密码）、xss蠕虫（利用xss漏洞进行传播）、修改网页代码（必须存在存储型xss漏洞，并且将结果返回到页面上）、利用网站重定向、获取用户信息（如浏览器信息，IP地址等）。&lt;/p&gt;

&lt;p&gt;3.CSRF的过程，会读数据吗？CSRF可以读数据，如2007年的Gmail CSRF漏洞，邮箱的Filter中会新创建一条规则，将所有带附件的邮件都转发到攻击者的邮箱中。&lt;/p&gt;

&lt;p&gt;token除了可以放在post包里面，还可以放在那里？用户的Session中，或者浏览器的cookie中。&lt;/p&gt;

&lt;p&gt;4.堡垒机是干什么的？（自己给自己挖的坑吧）
    运维堡垒主机是种具备强大防御功能和安全审计功能的服务器。基于跳板机理念，作为内外网络的个安全审计监测点，以达到把所有网站安全问题集中到某台服务器上解决，从而省时省力。同时运维堡垒主机还具备了，对运维人员的远程登录进行集中管理的功能作用。&lt;/p&gt;

&lt;p&gt;5.python的多线程、&lt;a href=&quot;http://blog.csdn.net/you_are_my_dream/article/details/56316826&quot;&gt;多进程&lt;/a&gt;,可能我还是需要把我辣鸡的小爬虫做成多线程的看看，回答起来才更有底气啊。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;背景：
    &lt;ul&gt;
      &lt;li&gt;GIL(Global Interpreter Lock):全局解释器锁&lt;/li&gt;
      &lt;li&gt;每个CPU在同一时间只能执行一个线程&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;多线程执行方式：
    &lt;ul&gt;
      &lt;li&gt;获取GIL&lt;/li&gt;
      &lt;li&gt;执行代码知道sleep或者是python虚拟机将其挂起&lt;/li&gt;
      &lt;li&gt;释放GIL&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;在Python2.x里，GIL的释放逻辑是当前线程遇见IO操作或者ticks计数达到100，而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源&lt;/li&gt;
  &lt;li&gt;是否多线程无用？
    &lt;ul&gt;
      &lt;li&gt;CPU密集型代码（循环、计数等），由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对&lt;code class=&quot;highlighter-rouge&quot;&gt;CPU密集型代码并不友好!!!!!!!!&lt;/code&gt;。&lt;/li&gt;
      &lt;li&gt;IO密集型代码（文件处理、爬虫等），多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对&lt;code class=&quot;highlighter-rouge&quot;&gt;IO密集型代码比较友好&lt;/code&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;多核多线程比单核多线程更差，原因是单核下多线程，每次释放GIL，唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，这样会造成线程颠簸(thrashing)，导致效率更低&lt;/li&gt;
  &lt;li&gt;python下想要充分利用多核CPU，就用多进程,每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，所以在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;6.&lt;a href=&quot;http://tech.ifeng.com/a/20180305/44895634_0.shtml&quot;&gt;DrDDoS&lt;/a&gt;为什么能放大5w倍：
Memcached的key-value功能。前文提到key-value的作用是决定存储容量的大小，正常情况下key-value的值通常不超过几千字节。当Memcached被攻击者利用作为反射器时，key-value的值经过修改可以达到100万字节以上。&lt;/p&gt;

&lt;p&gt;http://www.freebuf.com/vuls/164864.html&lt;/p&gt;

&lt;p&gt;7.C++ 为什么能继承（这个我再想想，可能我是把问题听错了）&lt;/p&gt;

&lt;p&gt;8.windows防御机制，哪个是第一个出现的？ASLR、DEP、GS&lt;/p&gt;

&lt;p&gt;9.Java反序列化，这个我要去具体分析几个poc了，要不然说起来真是没底气啊&lt;/p&gt;

&lt;p&gt;10.平时会看书吗？我说了在看兜哥的《web安全深度学习实战》，问我具体的章节问题，里面的demo我都还没试啊，懒惰如我…&lt;/p&gt;

&lt;p&gt;11.做过渗透测试吗：准备做一些 &lt;a href=&quot;hackthebox.eu&quot;&gt;hackbox&lt;/a&gt;上面的题目弥补无渗透经验的缺陷T.T&lt;/p&gt;

&lt;h3 id=&quot;腾讯二面-2018-03-20&quot;&gt;腾讯二面 2018-03-20&lt;/h3&gt;

&lt;p&gt;好像被分到支付反欺诈的部门了…小哥哥一直在问机器学习相关的东西…&lt;/p&gt;

&lt;p&gt;搜了下支付安全，没有搜到很多技术文，&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24882985&quot;&gt;从支付宝安全漏洞开始，谈谈机器学习与业务规则，再八卦下人工智能&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;我们来做一个模型，来判断一下当前这个想登录支付宝的用户是不是账号的本人。那么特征工程怎么做呢？考虑的并非仅仅是用户通过了几个安全问题的回答（这个仅仅是实时特征），还有用户基础属性和长期积累的行为。

先不说用户能通过哪几个安全问题，仅仅从用户基础属性和长期行为观察，都可以推测出用户被盗的风险。

举个简单的例子，文化水平低的用户账号容易被盗，在淘宝上经常购买XX商品的用户账号容易被盗，经常在外面开房的用户账号容易被盗等等。

于是乎，提取一堆离线特征，性别，文化水平，区域，购物偏好，酒店订单次数等等.

训练样本也是有的，用户投诉反馈被盗的用户作为正样本，随机挑一些其他用户作为负样本.

然后开始上机器学习算法，贝叶斯，决策树，逻辑回归，gbdt等等，挑挑参，看看ROC和AUC，选择一个最好的上线。

听说做风控的要求变量的可解释性，因此会做一些特征选择方面的工作，比如相关性过高的特征只保留一个。

于是，线上的安全策略模型就是通过账号被盗风险+实时特征（当前网络环境和通过的安全问题）来判断当前用户是账号本人。

比如你的账号被盗风险是0.3，在之前的WIFI下登录，通过了2个安全问题，那么你很可能通过了。

再比如你的账号被盗风险是0.9，在一个全新的WIFI下登录，也许你连回答安全问题的资格都没有。所以，并不是所有人都可以绕过手机验证码，通过回答安全问题进行密码修改的。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;得把机器学习相关的基础知识点好好看看，一个机器学习的具体过程是什么，如何选模型&lt;/p&gt;

&lt;p&gt;审计规则怎么定&lt;/p&gt;

&lt;p&gt;基础算法还是得看看啊，快排什么的&lt;/p&gt;

&lt;p&gt;态势感知到底在做什么&lt;/p&gt;

&lt;p&gt;自己到底擅长什么&lt;/p&gt;

&lt;h3 id=&quot;腾讯-2018-03-22&quot;&gt;腾讯 2018-03-22&lt;/h3&gt;

&lt;p&gt;TEG部门的小哥哥，问的都是我简历上面的东西，但是想要深入问下去我就都不会了&lt;/p&gt;

&lt;p&gt;最近准备分析个office的宏病毒&lt;/p&gt;

&lt;p&gt;做几个waf绕过的实验&lt;/p&gt;

&lt;h3 id=&quot;腾讯-2018-03-26&quot;&gt;腾讯 2018-03-26&lt;/h3&gt;

&lt;p&gt;TEG部门小哥哥二面，这个小哥哥好温柔&lt;/p&gt;

&lt;p&gt;技术问题如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ SSRF
+ memcache的drDoS如何防御：
    + memcache使用者：升级最新版本，监听端口随机，将服务放置于可信域内，添加安全组,查看set命令后value的大小是否超过阈值，过滤对外发送的虚假ip报文
    + 被攻击方：流量清洗（how？？？）[互联网创业公司如何防御 DDoS 攻击？](https://www.zhihu.com/question/19581905)
+ 如何审计网站上面的sql注入
+ 如何绕过waf
+ windows保护机制除了GS、ASLR、DEP还有什么，有零页禁用、高熵随机化、[执行流保护（Control Flow Guard , CFG）](http://www.freebuf.com/articles/security-management/58373.html)、管理模式执行保护（Superior Mode Execution Prevention, SMEP）等等。
    [windows安全机制](https://blog.csdn.net/moshangyanyuyao/article/details/17320715)
+ 卷积的原理，为什么高效
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其他就是很多安全学习的问题，为什么要做安全，自己有什么优点（这个我得好好想想，夸夸自己啊），以后的职业规划什么的。&lt;/p&gt;

&lt;h3 id=&quot;腾讯-2018-03-29&quot;&gt;腾讯 2018-03-29&lt;/h3&gt;

&lt;p&gt;三面是两个大叔，就跟一个大叔聊着聊着，突然又有一个大叔在问我问题，吓哭我😂&lt;/p&gt;

&lt;p&gt;第一个大叔主要还是围绕简历来问，蜜饵文档的制作，我可能还需要回去看看代码了。&lt;/p&gt;

&lt;p&gt;函数怎么压栈，爬虫的多线程代理池自己写过没，用户访问网站会发生什么交互（这边我直接讲了https的握手过程…）&lt;/p&gt;

&lt;p&gt;shell脚本我还需要学习下&lt;/p&gt;

&lt;p&gt;第二个大叔问了我很多深度学习相关的东西，介绍下项目用的模型，然后说我基础不错😊&lt;/p&gt;

&lt;h3 id=&quot;阿里-2018-03-29&quot;&gt;阿里 2018-03-29&lt;/h3&gt;

&lt;p&gt;下午内推了阿里云盾，当天晚上接到面试电话，面完了才知道面试官是帮我内推的小哥哥🤣&lt;/p&gt;

&lt;p&gt;主要是根据简历来问的，就是想要看里面写的项目是不是真的是自己做的。&lt;/p&gt;

&lt;p&gt;有个问题是问我知不知道语料库如何采集，可能是有什么官方的方法吗，我得查查资料。&lt;/p&gt;

&lt;p&gt;我项目里面的一些代码是直接copy人家git上面的源码，觉得能实现功能就好了，也没深究代码的意义，然后被问得很虚。&lt;/p&gt;

&lt;p&gt;另外我觉得如果想要进某个部门的话，就必须深入了解这个部门的产品线。我可能最近没事就打开云盾主页，看他们家的产品介绍🤣，所以这个小哥哥对我这点还是很满意的&lt;/p&gt;

&lt;p&gt;另外会问优缺点啥的，稍微准备下就好&lt;/p&gt;

&lt;h3 id=&quot;腾讯-2018-03-30&quot;&gt;腾讯 2018-03-30&lt;/h3&gt;

&lt;p&gt;腾讯四面，还是技术面，让我介绍项目&lt;/p&gt;

&lt;p&gt;最后问了我一个月有31天的话，第二个周三可能是第几天，我回答得太惨了，可能是挂了吧🤣🤣🤣🤣🤣&lt;/p&gt;

&lt;p&gt;鹅厂的面试基本贯穿了我这个月的面试流程，挂了的话是不是可以4月5号笔试之后再面一波🤣🤣🤣🤣🤣&lt;/p&gt;

&lt;p&gt;段少说我可以到时候写个帖子，说鹅厂面了我10面，最后把我给刷了😤😤😤😤😤&lt;/p&gt;

&lt;h3 id=&quot;腾讯-2018-04-02&quot;&gt;腾讯 2018-04-02&lt;/h3&gt;

&lt;p&gt;腾讯teg的安全云二面，之前那个部门就是挂了啊&lt;/p&gt;

&lt;p&gt;问了我我如何识别垃圾短信&lt;/p&gt;

&lt;p&gt;国民经济平均值报表发出来，大家都说自己达不到平均收入，如何看待&lt;/p&gt;

&lt;p&gt;了解正态分布吗&lt;/p&gt;

&lt;p&gt;鱼妹说我这种面了三个部门的只此一家了，现在总共加起来腾讯有7面了，估计也是凉凉了🤣&lt;/p&gt;

&lt;h3 id=&quot;阿里-2018-04-02&quot;&gt;阿里 2018-04-02&lt;/h3&gt;

&lt;p&gt;阿里云二面，小哥哥的评价是总体还行，具体细节还需要加强。就算凉了我也是服气的，毕竟自己学的太粗浅了，很多分明知道的东西也不去深究&lt;/p&gt;

&lt;p&gt;HTTP协议解析(是不是这个问题来着…)，反正就是要问burp抓到的包里面HTTP请求头有哪些&lt;/p&gt;

&lt;p&gt;GET、POST、OPTION等请求方式的区别&lt;/p&gt;

&lt;p&gt;XSS在输入检查还是输出编码处防御好&lt;/p&gt;

&lt;p&gt;web指纹技术&lt;/p&gt;

&lt;p&gt;session与cookie的区别&lt;/p&gt;

</description>
        <pubDate>Fri, 16 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6/</guid>
        
        <category>sec</category>
        
        
      </item>
    
      <item>
        <title>Word2Vec以及tf实现</title>
        <description>&lt;h3 id=&quot;引言&quot;&gt;引言？&lt;/h3&gt;

&lt;p&gt;大部分内容摘自《TensorFlow实战》（黄文坚），算是读书笔记，也会在网上搜集一些相关的文章进行补充。
我觉得这本书很nice呀，虽然没有对具体的神经网络进行详细的讲解，但是很通俗易懂，偏实战。
也会有看了神经网络的详解然后雨里雾里，再在这边看了总结的豁然开朗之感。&lt;/p&gt;

&lt;h3 id=&quot;one-hot-encoder&quot;&gt;One-Hot Encoder&lt;/h3&gt;

&lt;p&gt;最早的词向量表示方法为One-Hot Encoder，将字词转成离散的单独的符号：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;杭州 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0]
上海 [0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0]
宁波 [0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0]
北京 [0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;杭州、上海、宁波、北京各对应一个向量，向量中只有一个值为1，其余都为0。
使用One-Hot Encoder有一个问题，即对特征的编码是随机的，没有考虑到字词之间的关系。如北京、上海应该聚集到一起，华盛顿、纽约聚集在一起。并且效率低、计算麻烦。&lt;/p&gt;

&lt;h3 id=&quot;什么是word2vec&quot;&gt;什么是Word2Vec&lt;/h3&gt;

&lt;p&gt;循环神经网络是在NLP领域最常使用的神经网络，而Word2Vec则是将语言中的字词转化为计算机可以理解的稠密向量（Dense Vector），通过一个嵌入空间使得语义上相似的单词在该空间内距离很近。&lt;/p&gt;

&lt;p&gt;Word2Vec分为：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CBOW（Continuous Bag of Words）:从原始语句（例如：中国的首都是____）推测目标字词（例如：北京）

Skip-Gram:从目标字词推测出原始语句，在大型语料库中表现更好
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;负采样&lt;/code&gt;：在Word2Vec的CBOW模型中，只训练一个二分类模型，区分真实的目标词汇和编造的噪声词汇（Negative Sampling）。只需要计算随机选择的k个词汇而并非全部。在实际中，使用Noise-Contrastive Estimation（NCE）Loss，在tf中对应为&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.nce_loss()&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;模型拆解&quot;&gt;模型拆解&lt;/h3&gt;

&lt;p&gt;Word2Vec模型其实就是简单化的神经网络：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//1.jpg&quot; height=&quot;500&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图片来源:&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27234078&quot;&gt;理解 Word2Vec 之 Skip-Gram 模型&lt;/a&gt;,作者写的超级详细，可以去读读。&lt;/p&gt;

&lt;p&gt;输入是One-Hot Vector。
如果想要用300个特征来表示一个单词，则隐藏层的维度为300，且Hidden Layer没有激活函数。
Output Layer维度跟Input Layer的维度一样，用的是Softmax回归，输出概率分布。&lt;/p&gt;

&lt;p&gt;将从输入层到隐含层的那些权重，作为每一个词汇表中的词的向量。&lt;/p&gt;

&lt;p&gt;因为One-Hot Vector十分稀疏，消耗大量的计算资源。为了进行高效计算，只要选择选择矩阵中对应的向量中维度值为1的索引行：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//4.jpg&quot; height=&quot;150&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边向量中取值为1的对应维度为3（下标从0开始），那么计算结果就是矩阵的第3行（下标从0开始）—— [10, 12, 19]，这样模型中的隐层权重矩阵便成了一个”查找表“（lookup table）&lt;/p&gt;

&lt;p&gt;详细拆解参考&lt;a href=&quot;http://www.sohu.com/a/128794834_211120&quot;&gt;如果看了此文还不懂 Word2Vec，那是我太笨&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CBOW&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将一个词所在的上下文中的词作为输入，而那个词本身作为输出，也就是说，看到一个上下文，希望大概能猜出这个词和它的意思。通过在一个大的语料库训练，得到一个从输入层到隐含层的权重模型。如下图所示，第l个词的上下文词是i，j，k，那么i，j，k作为输入，它们所在的词汇表中的位置的值置为1。然后，输出是l，把它所在的词汇表中的位置的值置为1。训练完成后，就得到了每个词到隐含层的每个维度的权重，就是每个词的向量。例如第i个词的词向量为&lt;code class=&quot;highlighter-rouge&quot;&gt;(Wi,1 Wi,2...Wi,m)&lt;/code&gt;,m为向量的维度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//2.jpeg&quot; height=&quot;500&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Skip-gram&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将一个词所在的上下文中的词作为输出，而那个词本身作为输入，也就是说，给出一个词，希望预测可能出现的上下文的词。通过在一个大的语料库训练，得到一个从输入层到隐含层的权重模型。如下图所示，第l个词的上下文词是i，j，k，那么i，j，k作为输出，它们所在的词汇表中的位置的值置为1。然后，输入是l，把它所在的词汇表中的位置的值置为1。训练完成后，就得到了每个词到隐含层的每个维度的权重，就是每个词的向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/Word2Vec//3.jpeg&quot; height=&quot;500&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tf实现word2vec&quot;&gt;tf实现Word2Vec&lt;/h3&gt;

&lt;p&gt;使用Skip-Gram模式的Word2Vec，以“the quick brown fox jumped over the lazy dog”为例，训练样本为(quick,the)，(quick,brown),(brown,quick),(brown,fox)等。训练时，希望模型可以从目标词汇quick推测出语境the，同时也需要制造随机的词汇作为负样本（噪声）。使用SGD（随机梯度下降算法）来更新模型中Word Embedding的参数，让概率分布的损失函数(NCE Loss)尽可能小。这样每个单词的Embedded Vector就会随着训练过程不断调整，直到处于一个最合适语料的空间位置。&lt;/p&gt;

&lt;p&gt;基本每一句都有注释啦，可以结合原书来看此段代码😳&lt;/p&gt;

&lt;p&gt;啊啊啊，我手工巧了一遍代码，才发现代码居然是tf上的&lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py&quot;&gt;demo&lt;/a&gt;…&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# -*- coding: UTF-8 -*-&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;zipfile&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# ---------------------------  数据预处理---------------------------&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'http://mattmahoney.net/dc/'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   从‘http://mattmahoney.net/dc’下载文本文件，里面约有17005207个用空格分隔好的英文句子。&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maybe_download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;statinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statinfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expected_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Found and verified'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statinfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'Failed to verify'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'. Can you get to it with a browser?'&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maybe_download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text8.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31344016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   filename = &quot;text8.zip&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   解压文件，并使用`tf.compat.as_str`将数据转化成单词列表。&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;namelist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Data size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   创建vocabulary词汇表,选取前50000频数的单词，其余单词认定为Unknown，编号为0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'UNK'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---------------------------------&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   collections.Counter统计单词列表中单词的频数&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   most_common 取top 50000频数的单词作为vocabulary&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   count = [(单词1,词频1),(单词2,词频2),...]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most_common&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   存入dic中&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  

    &lt;span class=&quot;c&quot;&gt;#   遍历单词列表，如果出现在dictionary中，则转化为编号。不在则为0。&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;unk_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;unk_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unk_count&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   字典的反转形式，可用编号查询出对应的单词&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   删除原始单词列表，节约内存&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   打印最高频出现的词汇及数量，[['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Most common words (+UNK)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   打印data前10个单词&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Sample data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   ---------------------------生成Word2Vec的训练样本---------------------------&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   使用Skip-Gram模式，将原始数据：&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   “the quick brown fox jumped over the lazy dog”转化为：&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   (quick,the)，(quick,brown),(brown,quick),(brown,fox)等。&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#  生成训练用的batch数据&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   skip_window 单词最远可以联系的距离&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   num_skips 对每个单词生成多少样本&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;#   定义为全局变量，因为会反复调用此函数&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   batch_size 必须为num_skips的整数倍，确保每个batch包含一个词汇对应的所有样本&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   ndarray对象是用于存放同类型元素的多维数组&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   某个单词创建样本时会使用到的单词数量,包括单词本身和它前后的单词&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;span&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   双向队列，使用append方法添加变量时，只会保留最后插入span个变量&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deque&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;c&quot;&gt;#   从序号data_index开始，把span个单词顺序读入buffer作为初始值&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# // 为整数除法&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;#   buffer中第skip_window个变量为目标单词&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;targets_to_avoid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;#   生成样本时需要避免的单词列表&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets_to_avoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;targets_to_avoid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#   简单测试功能&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   训练数据&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 单词转为稠密向量的维度，一般是50~1000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 单词间最远可以联系的距离 &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 每个目标单词提取的样本数&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   验证数据，随机抽取一些频数最高的单词，看向量空间上跟它们最近的单词是否相关性比较高&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 抽取的验证单词数&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 验证单词只从频数最高的100个单词中抽取&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_examples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_sampled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 训练时用来做负样本的噪声单词的数量&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   ---------------------------定义Skip-Gram模型的网络结构---------------------------&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   将随机产生的valid_examples转换为constant&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;valid_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/cpu:0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   tf.random_uniform随机生成所有单词的词向量embeddings,单词表大小为50000，向量维度为128&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   tf.nn.embedding_lookup 查找输入train_inputs对应的向量&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   使用NCE Loss作为训练的优化目标&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nce_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;truncated_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nce_biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   loss的计算方式&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nce_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nce_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nce_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;num_sampled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_sampled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocabulary_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;#   定义优化器为SGD，lr为1.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   计算嵌入向量embeddings的L2范数norm&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   规范化&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   tf.nn.embedding_lookup 查询验证单词的嵌入向量&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;valid_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   计算验证单词的嵌入向量与词汇表中所有单词的相似性&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;similarity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#   初始化所有模型参数&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   最大的迭代次数&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100001&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Initialized&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   生成一个batch的inputs和labels数据&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_skips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_val&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# 2000此循环，计算一下平均loss并显示出来&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Average loss at step &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;average_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

        &lt;span class=&quot;c&quot;&gt;# 每10000次循环，计算一次验证单词与全部单词的相似度，并将最相似的8个单词展示出来&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;valid_word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Nearest to &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_word&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;close_word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;c&quot;&gt;#close_word = reverse_dictionary.get(nearest[k])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s ,&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;final_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized_embeddings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#   ---------------------------可视化---------------------------&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# low_dim_embs 是降维到2维的单词的空间向量，在图表中展示每个单词的位置&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;plot_with_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'tsne.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;More labels than embeddings&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 显示散点图（单词的位置）&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# plt.annotate为单词本身&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;annotate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;     
                     &lt;span class=&quot;n&quot;&gt;xy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;xytext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;textcoords&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'offset points'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;ha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'right'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;va&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bottom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;#   保存图片到本地&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 降维,将原始的128维嵌入向量降到2维，展示词频最高的100个单词&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.manifold&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perplexity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pca&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_only&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_only&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverse_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_only&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_with_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_dim_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Sat, 10 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/Word2Vec/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/Word2Vec/</guid>
        
        <category>AI</category>
        
        
      </item>
    
      <item>
        <title>安全岗面试相关问题--网络相关</title>
        <description>&lt;h3 id=&quot;怎么又要开始准备面试了&quot;&gt;怎么又要开始准备面试了&lt;/h3&gt;
&lt;p&gt;下面总结的内容都比较简略，可能是摘抄了《白帽子》，可能是网上搜集的资料，或者直接给出了别人总结的很好的文章供以后查看，因为每个点展开来将都可以写好几篇文章（嗯，为自己偷懒找借口&lt;/p&gt;

&lt;h3 id=&quot;osi七层模型&quot;&gt;OSI七层模型&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/网络//osi.png&quot; height=&quot;400&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tcp&quot;&gt;TCP&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/li_ning_/article/details/52117463&quot;&gt;TCP与UDP的区别&lt;/a&gt;
&lt;img src=&quot;/images/posts/2018/03/网络//tcpudp.png&quot; height=&quot;250&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/xulu_258/article/details/51146489&quot;&gt;三次握手&lt;/a&gt;
&lt;img src=&quot;/images/posts/2018/03/网络//三次.jpeg&quot; height=&quot;400&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;四次握手
&lt;img src=&quot;/images/posts/2018/03/网络//四次.jpeg&quot; height=&quot;500&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为何连接的时候是三次，关闭的时候是四次
  因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dns解析&quot;&gt;DNS解析&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/网络//dns.jpg&quot; height=&quot;500&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/23042131/answer/66571369&quot;&gt;知乎&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在浏览器中输入www  . qq  .com 域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。&lt;/li&gt;
  &lt;li&gt;如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。&lt;/li&gt;
  &lt;li&gt;如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的&lt;code class=&quot;highlighter-rouge&quot;&gt;首选DNS服务器&lt;/code&gt;，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。&lt;/li&gt;
  &lt;li&gt;如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。&lt;/li&gt;
  &lt;li&gt;如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(http://qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找http://qq.com域服务器，重复上面的动作，进行查询，直至找到www  . qq  .com主机。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DNS在进行&lt;a href=&quot;https://www.cnblogs.com/lca1826/p/6599269.html&quot;&gt;区域传输&lt;/a&gt;的时候用TCP，其他时候用UDP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.williamlong.info/archives/3356.html&quot;&gt;DNS劫持与污染&lt;/a&gt;：
    &lt;ul&gt;
      &lt;li&gt;DNS劫持就是指用户访问一个被标记的地址时，DNS服务器故意将此地址指向一个错误的IP地址的行为。范例，网通、电信、铁通的某些用户有时候会发现自己打算访问一个地址，却被转向了各种推送广告等网站，这就是DNS劫持。&lt;/li&gt;
      &lt;li&gt;DNS污染，指的是用户访问一个地址，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。范例，访问Youtube、Facebook之类网站等出现的状况。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;https相关&quot;&gt;HTTPS相关&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/kobejayandy/article/details/52433660&quot;&gt;https的原理&lt;/a&gt;
  &lt;img src=&quot;/images/posts/2018/03/网络//https.jpg&quot; height=&quot;500&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/RIcZNMUWd8P7Quel4vU_Yg&quot;&gt;HTTPS 协议降级攻击原理&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;由客户端（如浏览器）发送第一个数据包 ClientHello，这个数据包中保存着客户端支持的&lt;code class=&quot;highlighter-rouge&quot;&gt;加密协议版本&lt;/code&gt;。&lt;/li&gt;
      &lt;li&gt;服务器收到这个ClientHello数据包，查看里面客户端支持的加密协议版本，然后匹配服务器自己支持的加密协议版本，从而确认双方应该用的加密协议版本。&lt;/li&gt;
      &lt;li&gt;服务器发送ServerHello数据包给客户端，告诉客户端要使用什么加密协议版本。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;如果客户端声称自己只支持某个旧版本有漏洞的加密协议，且服务器支持此协议，则攻击有可能发生。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https流量如何检测:这个问题是不是类似于用&lt;a href=&quot;http://blog.csdn.net/zyw_anquan/article/details/47904495&quot;&gt;burp&lt;/a&gt;抓包的问题啊，下载CA证书，导入到浏览器，并设置为信任。（待补充吧&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;拒绝服务攻击&quot;&gt;拒绝服务攻击&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/26828198&quot;&gt;浅谈DDoS攻击与防御&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;网络层DDoS攻击
    &lt;ul&gt;
      &lt;li&gt;SYN flood:三次握手的缺陷；措施：SYN cookie/SYN Proxy、safereset算法等&lt;/li&gt;
      &lt;li&gt;UDP flood：UDP是一种无连接的协议，伪造大量的源IP去发送UDP包。但UDP包双向流量基本对等，也会消耗自身资源&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ICMP flood：不断发送不正常的ICMP包（内容很大，占带宽）。目前很多服务器禁ping(防火墙可以屏蔽)。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;防御：
        &lt;ul&gt;
          &lt;li&gt;网络架构优化，采用负载均衡&lt;/li&gt;
          &lt;li&gt;添加抗DDoS设备，流量清洗&lt;/li&gt;
          &lt;li&gt;限制单IP请求频率&lt;/li&gt;
          &lt;li&gt;防火墙等保护设置禁止icmp包等&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;应用层DDoS
    &lt;ul&gt;
      &lt;li&gt;CC攻击：
        &lt;ul&gt;
          &lt;li&gt;对一些消耗资源较大的应用页面不断发起正常的请求，如数据库查询；&lt;/li&gt;
          &lt;li&gt;篡改流量大的A网站页面，加入&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;iframe src = &quot;target&quot;&amp;gt;&lt;/code&gt;，则每当有人访问A，则也会对目标站发起get请求。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Slowloris攻击：以极低的速度往服务器发送http请求（完整的http头是的结尾是&lt;code class=&quot;highlighter-rouge&quot;&gt;\r\n\r\n&lt;/code&gt;）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;HTTP POST DoS:发送http post包时，指定一个非常大的content-length值，再以很低的速度发包&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Server Limit DoS:这是由于cookie导致的dos攻击，当然其原理还是基于webserver的特性。apache默认最大的http包头长度为8192字节，如果超出此长度，则会返回4xx错误。如果我们利用存储型xss漏洞，将一个超长的cookie写入客户端页面，则用户再访问此页面后，由于请求头加载了恶意的超长cookie，导致其不能访问该站的页面（除非清空cookie）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;ReDoS:代码写得有缺陷，导致使用正则时，会出现大量占用资源的情况，导致服务不可用&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;措施：
        &lt;ul&gt;
          &lt;li&gt;使用频率高的数据放在memcache中（最近有新闻报道&lt;a href=&quot;http://www.freebuf.com/company-information/163963.html&quot;&gt;Memcached&lt;/a&gt;的安全漏洞导致github被大规模DDoS）&lt;/li&gt;
          &lt;li&gt;网络架构优化，充分利用好CDN和镜像站点的分流作用&lt;/li&gt;
          &lt;li&gt;限制请求频率，通过IP地址+Cookie定位一个客户端&lt;/li&gt;
          &lt;li&gt;验证码（验证过程：对比用户提交的明文和服务器端Session里存放的验证码明文是否一致）&lt;/li&gt;
          &lt;li&gt;判断UA（不可靠）&lt;/li&gt;
          &lt;li&gt;让客户端解析一段JS（不可靠）（类似于区块链里面的Hashcash）&lt;/li&gt;
          &lt;li&gt;Apache的配置文件里，调小timeout、keepalivetimeout，增加maxclients，合理配置中间件&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 09 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>安全岗面试相关问题--web常见漏洞原理与防御</title>
        <description>&lt;h3 id=&quot;怎么又要开始准备面试了&quot;&gt;怎么又要开始准备面试了&lt;/h3&gt;
&lt;p&gt;下面总结的内容都比较简略，可能是摘抄了《白帽子》，可能是网上搜集的资料，或者直接给出了别人总结的很好的文章供以后查看，因为每个点展开来将都可以写好几篇文章（嗯，为自己偷懒找借口&lt;/p&gt;

&lt;h3 id=&quot;xss&quot;&gt;XSS&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;常见类型：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;反射型XSS：把用户输入的数据“反射”给浏览器，即需要用户点击某链接&lt;/li&gt;
      &lt;li&gt;存储型XSS：把用户输入的数据存储在服务器&lt;/li&gt;
      &lt;li&gt;DOM Based XSS：也属于反射型XSS，修改页面的DOM节点形成XSS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其他类型的XSS：&lt;a href=&quot;http://www.fooying.com/the-art-of-xss-1-introduction/&quot;&gt;跨站的艺术-XSS入门与介绍&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;mXSS:突变型XSS，原本无害，而由于一些特殊原因，如反编码等，导致Payload发生变异，导致的XSS。如：旧版QQ客户端中的链接预览。&lt;/li&gt;
      &lt;li&gt;UXSS:利用浏览器或者浏览器扩展漏洞来制造产生XSS的条件并执行代码的一种攻击类型,可以理解为Bypass同源策略。&lt;a href=&quot;http://www.fooying.com/uxss/&quot;&gt;通用跨站脚本攻击(UXSS)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Flash XSS:来源于 getURL/navigateToURL（访问跳转）、ExternalInterface.call（调用js函数）&lt;/li&gt;
      &lt;li&gt;UTF-7 XSS:低版本IE中未指定meta编码或指定编码为UTF-7&lt;/li&gt;
      &lt;li&gt;MHTML XSS:低版本IE中&lt;/li&gt;
      &lt;li&gt;CSS XSS:&lt;code class=&quot;highlighter-rouge&quot;&gt;body {width:expression(alert(1));: red;}&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;VBScript XSS:&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;input type =&quot;button&quot; onClick=&quot;VBScript:Document.Write 'hello mr. Fooying' MsgBox 'xss'&quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;注入点：
  GET参数、POST参数、UA、Referer…一切可以提交的输入点&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;危害：&lt;a href=&quot;https://thief.one/2017/05/31/1/&quot;&gt;浅谈跨站脚本攻击与防御&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;cookie劫持&lt;/li&gt;
      &lt;li&gt;后台增删改文章&lt;/li&gt;
      &lt;li&gt;钓鱼，利用xss构造出一个登录框，骗取用户账户密码。&lt;/li&gt;
      &lt;li&gt;xss蠕虫（利用xss漏洞进行传播）&lt;/li&gt;
      &lt;li&gt;修改网页代码:必须存在存储型xss漏洞，并且将结果返回到页面上
  （javascript加载外部的代码文件可以是任意扩展名（无扩展名也可以））&lt;/li&gt;
      &lt;li&gt;利用网站重定向&lt;/li&gt;
      &lt;li&gt;获取用户信息（如浏览器信息，IP地址等）:调用java Applet的接口获取客户端本地IP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;防御：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;在Cookie中设置&lt;code class=&quot;highlighter-rouge&quot;&gt;HttpOnly&lt;/code&gt;标识,禁止页面的js访问带有httponly属性的cookie&lt;/li&gt;
      &lt;li&gt;XSS Filter：过滤用户输入的危险字符，设置黑白名单&lt;/li&gt;
      &lt;li&gt;输出检查：编码和转义，常用编码：html编码、url编码、js编码、16进制、base64等，使得浏览器无法解析执行js代码&lt;/li&gt;
      &lt;li&gt;针对不同位置的输出，使用不同的处理方式&lt;/li&gt;
      &lt;li&gt;处理富文本:限制用户能使用的标签，限制为只能使用a、div等安全的标签&lt;/li&gt;
      &lt;li&gt;header中使用content-Sencurity-Policy字段，规定请求js的域名白名单（CSP策略）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;绕过：
    &lt;ul&gt;
      &lt;li&gt;转换大小写&lt;/li&gt;
      &lt;li&gt;大小写混写&lt;/li&gt;
      &lt;li&gt;双引号改单引号&lt;/li&gt;
      &lt;li&gt;引号改为/&lt;/li&gt;
      &lt;li&gt;用全角字符&lt;/li&gt;
      &lt;li&gt;使用javascript伪协议&lt;/li&gt;
      &lt;li&gt;使用回车、空格等特殊字符&lt;/li&gt;
      &lt;li&gt;在css的style中使用/**/注释符&lt;/li&gt;
      &lt;li&gt;使用字符编码&lt;/li&gt;
      &lt;li&gt;利用事件触发xss&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;a href=&quot;https://security.yirendai.com/news/share/26&quot;&gt;浅谈XSS—字符编码和浏览器解析原理&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;常用payload：&lt;a href=&quot;https://www.t00ls.net/thread-42640-1-1.html&quot;&gt;t00ls&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sql-injection&quot;&gt;SQL Injection:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;原理：数据与代码未分离&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;数据库相关：
    &lt;ul&gt;
      &lt;li&gt;mysql 5.0版本以后提供了information.schema数据库：
  &lt;img src=&quot;/images/posts/2018/03/web/sql/1.png&quot; height=&quot;200&quot; width=&quot;300&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;查看该数据库中的表：schemata、tables、columns需要重点关注
  &lt;img src=&quot;/images/posts/2018/03/web/sql/2.png&quot; height=&quot;800&quot; width=&quot;500&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;schemata：所有数据库的基本信息，包括数据库名，编码类型，路径等。schema_name列即为数据库名。
  &lt;img src=&quot;/images/posts/2018/03/web/sql/3.png&quot; height=&quot;150&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
          &lt;li&gt;tables: 储存mysql中的表信息，table_schema是库名信息，table_nama是表名（图太大了，不截了）&lt;/li&gt;
          &lt;li&gt;columns：提供了表中的列信息，columns_name字段对应的字段名&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;系统函数：
        &lt;ul&gt;
          &lt;li&gt;user() ：当前使用者的用户名&lt;/li&gt;
          &lt;li&gt;database()：当前数据库名&lt;/li&gt;
          &lt;li&gt;version()：数据库版本&lt;/li&gt;
          &lt;li&gt;datadir：读取数据库的绝对路径&lt;/li&gt;
          &lt;li&gt;@@vasedir：mysql安装路径&lt;/li&gt;
          &lt;li&gt;@@version_compile_os：操作系统&lt;/li&gt;
          &lt;li&gt;concat()：连接一个或者多个字符串&lt;/li&gt;
          &lt;li&gt;group_concat()：连接一个组的所有字符串，并以逗号分隔每一条数据&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.51cto.com/wt7315/1828167&quot;&gt;分类&lt;/a&gt;：
    &lt;ul&gt;
      &lt;li&gt;基于联合查询
        &lt;ul&gt;
          &lt;li&gt;UNION:合并两个或多个SELECT语句的结果集，并消去表中重复的行。UNION 内部的 SELECT 语句必须拥有相同数量的列，列也必须拥有相似的数据类型。&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,version(),database()&lt;/code&gt;可以爆出当前使用的版本和数据库名&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,schema_name from information_schema.schemata limit 1,1 %23爆出数据库名，依次使用limit2，1往下爆库名&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(schema_name) from information_schema.schemata %23&lt;/code&gt;&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;假设有flag库：
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(table_name) from information_schema.tables where schema_name=’flag’&lt;/code&gt; 爆出flag库下的所有的表，假设其中有flagtable表&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(column_name) from information_schema.columns where table_name =’flagtale’&lt;/code&gt;爆出flagtable下的所有字段，假设有name和password字段&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and 1=2 union select 1,2,group_concat(name,password) from flag.flagtable&lt;/code&gt; 爆出flag下的flagtable表的name和password的内容&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.51cto.com/wt7315/1891458&quot;&gt;基于错误回显&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;用到的函数：
            &lt;ul&gt;
              &lt;li&gt;count():统计元祖的个数
   &lt;img src=&quot;/images/posts/2018/03/web/sql/4.png&quot; height=&quot;100&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;rand():0~1的随机数
   &lt;img src=&quot;/images/posts/2018/03/web/sql/5.png&quot; height=&quot;100&quot; width=&quot;250&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;floor():向下取整,select floor(rand()*2);的结果为0或者1
   &lt;img src=&quot;/images/posts/2018/03/web/sql/6.png&quot; height=&quot;200&quot; width=&quot;250&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;group_concat():将数据进行拼接
   &lt;img src=&quot;/images/posts/2018/03/web/sql/7.png&quot; height=&quot;100&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;整合语句：&lt;code class=&quot;highlighter-rouge&quot;&gt;select count(*),concat(0x3a,0x3a,database(),0x3a,floor(rand()*2))name from information_schema.tables group by name;&lt;/code&gt;
 &lt;img src=&quot;/images/posts/2018/03/web/sql/8.png&quot; height=&quot;200&quot; width=&quot;800&quot; /&gt;
            &lt;ul&gt;
              &lt;li&gt;生成随机数并取整，然后用分号将不同的数据拼接，并取别名name，最后将结果以name进行分组并进行统计，能看到统计出的两个不同的取值，0和1。&lt;/li&gt;
              &lt;li&gt;多重复几次就会报错
 &lt;img src=&quot;/images/posts/2018/03/web/sql/9.png&quot; height=&quot;30&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;公式：&lt;code class=&quot;highlighter-rouge&quot;&gt;username=admin' and (select 1 from (select count(*), concat(floor(rand(0)*2),0x23,(你想获取的数据的sql语句))x from information_schema.tables group by x )a) and '1' = '1&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;基于盲注
        &lt;ul&gt;
          &lt;li&gt;时间盲注:
            &lt;ul&gt;
              &lt;li&gt;加入特定的时间函数，通过查看是web页面返回的时间差来判断注入的语句是否正确&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;and if(ascii(substr((select schema_name from information_schema.schemata limit 1,1),1,1))&amp;gt;100,1,sleep(3))%23&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;布尔型的盲注: &lt;code class=&quot;highlighter-rouge&quot;&gt;and ascii(substr(@@datadir,1,1)）&amp;gt;69 %23&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;二次注入:分为语句插入和语句执行&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.91ri.org/8611.html&quot;&gt;宽字节注入&lt;/a&gt;:  （字符集好方啊，我得专门总结一篇啊😂
        &lt;ul&gt;
          &lt;li&gt;mysql的转义函数：&lt;code class=&quot;highlighter-rouge&quot;&gt;addslashes&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql_real_escape_string&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql_escape_string&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;的ascii码为&lt;code class=&quot;highlighter-rouge&quot;&gt;0x5c&lt;/code&gt;,会结合成新的字符&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.anquanke.com/post/id/85936&quot;&gt;其他&lt;/a&gt;：
        &lt;ul&gt;
          &lt;li&gt;读文件：SELECT LOAD_FILE(‘/etc/passwd’);&lt;/li&gt;
          &lt;li&gt;写文件：
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT '&amp;lt;? system($_GET['c']); ?&amp;gt;' INTO OUTFILE/DUMPFILE '/var/www/shell.php';&lt;/code&gt;&lt;/li&gt;
              &lt;li&gt;into dumpfile 能导出一个完整能执行的2进制文件,函数不对任何列或行进行终止，也不执行任何转义处理&lt;/li&gt;
              &lt;li&gt;在UDF提权的场景是需要上传二进制文件等等用dumpfile&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;带外通道：利用其他协议或者渠道从服务器提取数据. 它可能是HTTP（S）请求，DNS解析服务，SMB服务，Mail服务等.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.zerokeeper.com/web-security/sqlmap-usage-summary.html&quot;&gt;sqlmap的使用&lt;/a&gt;，最基础的使用方法如下：
    &lt;ul&gt;
      &lt;li&gt;sqlmap -u “xxx”&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” –current-db&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” -D DB名 –tables&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” -D DB名 -T 表名 –columns&lt;/li&gt;
      &lt;li&gt;sqlmap -u “xxx” -D DB名 -T 表名 -C 字段名 –dump&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.lengbaikai.net/?p=110&quot;&gt;tamper绕WAF&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;其他注入：
    &lt;ul&gt;
      &lt;li&gt;XML注入&lt;/li&gt;
      &lt;li&gt;代码注入&lt;/li&gt;
      &lt;li&gt;CRLF注入：\r\n,0x0d,0x0a&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;防御：
    &lt;ul&gt;
      &lt;li&gt;waf&lt;/li&gt;
      &lt;li&gt;使用预编译语句，绑定变量&lt;/li&gt;
      &lt;li&gt;检查数据类型，例如限制输入数据只能为int&lt;/li&gt;
      &lt;li&gt;使用安全函数,encodeForSQL()&lt;/li&gt;
      &lt;li&gt;最小权限原则，避免直接使用root&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;csrf&quot;&gt;CSRF:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;原理：通过伪装来自受信任用户的请求来利用受信任的网站,例如：用户登录某账户，浏览器获得cookie；攻击者诱使用户访问某构造好的恶意CSRF页面。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;防御：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;验证码&lt;/li&gt;
      &lt;li&gt;Referer Check（HTTPS跳转到HTTP不会发送Referer）&lt;/li&gt;
      &lt;li&gt;Anti CSRF Token&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ssrfserver-side-request-forgery&quot;&gt;SSRF（Server-Side Request Forgery）&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Snowty/Snowty.github.io/blob/master/images/others/1Build%2BYour%2BSSRF%2BExploit%2BFramework%2B%E2%80%94%E2%80%94%2B%E4%B8%80%E4%B8%AA%E5%8F%AA%E5%BD%B1%E5%93%8D%E6%9C%89%E9%92%B1%E4%BA%BA%E7%9A%84%E6%BC%8F%E6%B4%9E%C2%B7%E7%8C%AA%E7%8C%AA%E4%BE%A0.pdf&quot;&gt;猪猪侠的ppt&lt;/a&gt;
&lt;a href=&quot;https://www.cnblogs.com/s0ky1xd/p/5859049.html&quot;&gt;浅谈SSRF漏洞&lt;/a&gt;
&lt;a href=&quot;http://www.91ri.org/17111.html&quot;&gt;SSRF漏洞分析与利用&lt;/a&gt;
&lt;a href=&quot;https://joychou.org/web/phpssrf.html&quot;&gt;SSRF in PHP&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;原理：利用漏洞伪造服务器端发起请求，从而突破客户端获取不到数据限制，一般用来在外网探测或攻击内网服务&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;SSRF可以做什么：
    &lt;ul&gt;
      &lt;li&gt;扫描内部网络（FingerPrint）&lt;/li&gt;
      &lt;li&gt;向内部&lt;code class=&quot;highlighter-rouge&quot;&gt;任意主机&lt;/code&gt;的&lt;code class=&quot;highlighter-rouge&quot;&gt;任意端口&lt;/code&gt;发送精心构造的数据{Payload}&lt;/li&gt;
      &lt;li&gt;DoS（请求大文件，始终保持连接 keep-alive always）&lt;/li&gt;
      &lt;li&gt;暴力穷举（users/dirs/files）,利用File协议读取本地文件。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;阻碍：
    &lt;ul&gt;
      &lt;li&gt;服务器开启OpenSSL&lt;/li&gt;
      &lt;li&gt;服务器需要鉴权信息（Cookies &amp;amp; User：Pass）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;可利用的伪协议：&lt;code class=&quot;highlighter-rouge&quot;&gt;dict file ftp ftps gopher http https imap imaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftp &lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/web//ssrf.png&quot; height=&quot;400&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;绕过:&lt;a href=&quot;http://www.freebuf.com/articles/web/135342.html&quot;&gt;SSRF漏洞中绕过IP限制的几种方法总结&lt;/a&gt;， &lt;a href=&quot;http://www.runoob.com/regexp/regexp-syntax.html&quot;&gt;正则语法&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;将IP改写为8、16进制，10、16进制整数格式，以绕过正则&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;http://xip.io&lt;/code&gt;,访问这个网站的子域名&lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.0.1.xip.io&lt;/code&gt;，就会自动重定向到192.168.0.1，使用&lt;code class=&quot;highlighter-rouge&quot;&gt;http://tinyurl.com&lt;/code&gt;变短地址&lt;/li&gt;
      &lt;li&gt;利用解析URL所出现的问题，&lt;code class=&quot;highlighter-rouge&quot;&gt;http://www.baidu.com@192.168.0.1/&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;Redirect：302跳转绕过http协议限制，如在302.php里面写入&lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;file&lt;/code&gt;等&lt;/li&gt;
          &lt;li&gt;CRLF注入：WebLogic SSRF HTTP头注入（这个还不太懂，先马住👀👀👀👀👀👀👀👀👀👀👀👀👀👀👀）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/web//wb1.png&quot; height=&quot;300&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/images/posts/2018/03/web//wb2.png&quot; height=&quot;300&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/images/posts/2018/03/web//wb3.png&quot; height=&quot;300&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/images/posts/2018/03/web//we4.png&quot; height=&quot;300&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;通过各种非HTTP协议:&lt;code class=&quot;highlighter-rouge&quot;&gt;gopher&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;file&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;DNS Rebinding:第一次去请求DNS服务进行域名解析到第二次服务端去请求URL之间存在一个时间查，利用这个时间差，我们可以进行DNS 重绑定攻击。
  &lt;img src=&quot;/images/posts/2018/03/web/dnsrebinding.png&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt; 
  &lt;img src=&quot;/images/posts/2018/03/web/dns.png&quot; height=&quot;150&quot; width=&quot;500&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;防御：
    &lt;ul&gt;
      &lt;li&gt;对url参数进行过滤，过滤返回信息&lt;/li&gt;
      &lt;li&gt;限制请求端口为http常用的端口&lt;/li&gt;
      &lt;li&gt;内网IP黑名单&lt;/li&gt;
      &lt;li&gt;禁用不需要的协议&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;xxe&quot;&gt;XXE&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://thief.one/2017/06/20/1/&quot;&gt;浅谈XXE漏洞攻击与防御&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;XML基础：
    &lt;ul&gt;
      &lt;li&gt;XML声明、文档元素&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/u011479875/article/details/49637893&quot;&gt;DTD&lt;/a&gt;（Document Type Definitions）文档类型定义，为漏洞根源
        &lt;ul&gt;
          &lt;li&gt;内部声明：&lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE 根元素 [元素声明]&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;引用外部：&lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE 根元素 SYSTEM &quot;文件名&quot;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;关键字如下：
            &lt;ul&gt;
              &lt;li&gt;DOCTYPE（DTD的声明）&lt;/li&gt;
              &lt;li&gt;SYSTEM、PUBLIC（外部资源申请）&lt;/li&gt;
              &lt;li&gt;ENTITY（实体的声明）：
                &lt;ul&gt;
                  &lt;li&gt;分类：内置实体、字符实体、通用实体、参数实体、外部实体&lt;/li&gt;
                  &lt;li&gt;外部实体：&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;!ENTITY 实体名称 SYSTEM &quot;URI&quot;&amp;gt;&lt;/code&gt;,url中可用file、http、https、ftp等
  &lt;img src=&quot;/images/posts/2018/03/web/dtdentity.png&quot; height=&quot;200&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
                &lt;/ul&gt;

                &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE a [
      &amp;lt;!ENTITY content SYSTEM &quot;file:///etc/passwd&quot;&amp;gt;&lt;/span&gt;]&amp;gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;foo&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;&lt;span class=&quot;ni&quot;&gt;&amp;amp;content;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/foo&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
                &lt;/div&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;原理：应用程序解析XML输入时，没有禁止DTD引用外部实体的加载，导致可加载恶意外部文件，造成文件读取、命令执行、内网端口扫描、攻击内网网站、发起dos攻击等危害。
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;!ENTITY 实体名称 SYSTEM &quot;URI&quot;&amp;gt;&lt;/code&gt;,支持file、http、https、ftp等&lt;/li&gt;
      &lt;li&gt;触发的点往往是可以上传xml文件的位置，没有对上传的xml文件进行过滤，导致可上传恶意xml文件&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;利用：
    &lt;ul&gt;
      &lt;li&gt;任意文件读取（有回显）&lt;/li&gt;
      &lt;li&gt;blind xxe（无回显）：构建一条带外信道提取数据&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;防御：
    &lt;ul&gt;
      &lt;li&gt;使用开发语言提供的&lt;code class=&quot;highlighter-rouge&quot;&gt;禁用外部实体&lt;/code&gt;的方法&lt;/li&gt;
      &lt;li&gt;过滤用户提交的XML数据，过滤关键词：&amp;lt;!DOCTYPE和&amp;lt;!ENTITY，或者SYSTEM和PUBLIC。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_web%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E4%B8%8E%E9%98%B2%E5%BE%A1/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_web%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E4%B8%8E%E9%98%B2%E5%BE%A1/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>安全岗面试相关问题--同源策略与跨域</title>
        <description>&lt;h3 id=&quot;怎么又要开始准备面试了&quot;&gt;怎么又要开始准备面试了&lt;/h3&gt;
&lt;p&gt;上次准备面试还是15年大三的时候啊，真心是什么都不懂（虽然现在也是…会用wamp建个站就投了安全岗啊233…我真是哪里来的勇气…&lt;/p&gt;

&lt;p&gt;今天看到当年投阿里写的在线简历，真是惨不忍睹，估计当时HR看到了以为我是在搞笑吧🤣&lt;/p&gt;

&lt;p&gt;下面总结的内容都比较简略，可能是摘抄了《白帽子》，可能是网上搜集的资料，或者直接给出了别人总结的很好的文章供以后查看，因为每个点展开来将都可以写好几篇文章（嗯，为自己偷懒找借口&lt;/p&gt;

&lt;p&gt;然后，把CHYbeta大神的&lt;a href=&quot;https://github.com/CHYbeta/Web-Security-Learning&quot;&gt;Web-Security-Learning&lt;/a&gt;过一遍😳？&lt;/p&gt;

&lt;h3 id=&quot;什么是同源策略&quot;&gt;什么是同源策略&lt;/h3&gt;

&lt;p&gt;源就是&lt;code class=&quot;highlighter-rouge&quot;&gt;[主机，协议，端口名]&lt;/code&gt;的一个三元组。
（此外，cookie的同源策略是&lt;code class=&quot;highlighter-rouge&quot;&gt;[主机，端口名]&lt;/code&gt;，不包含协议，因此可以用http的cookie去覆盖https的cookie。）&lt;/p&gt;

&lt;p&gt;同源策略(Same Origin Policy, SOP)：限制了来自不同源的”document“或者脚本，对当前”document“读取或者设置某些属性。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script&amp;gt;、&amp;lt;img&amp;gt;、&amp;lt;iframe&amp;gt;、&amp;lt;link&amp;gt;&lt;/code&gt;等标签都可以跨域加载资源，而不受同源策略的限制，但是浏览器限制了JS的权限，使其不能读、写返回的资源。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;XMLHttpRequest&lt;/code&gt;不可以跨域加载资源，但是可以读写资源。如果可以跨域，则会导致一些敏感数据的泄漏，如CSRF Token。&lt;/p&gt;

&lt;p&gt;XHR需要根据&lt;code class=&quot;highlighter-rouge&quot;&gt;目标域&lt;/code&gt;返回的HTTP头来授权是否允许跨域访问，因为&lt;code class=&quot;highlighter-rouge&quot;&gt;JS无法控制HTTP头&lt;/code&gt;（这点非常重要啊啊啊啊啊啊，👻👽💀🤖👏👏👏）。XSS在没有其他辅助的情况下也无法控制HTTP头啊啊啊啊。&lt;/p&gt;

&lt;p&gt;除了DOM、Cookie、XHR受到同源策略的限制，第三方插件如Flash（crossdomain.xml、MIME）、Java、Applet等都有自己的同源策略。&lt;/p&gt;

&lt;p&gt;跨域的方式主要有：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CORS
CSP
JSONP
postMessage
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;cross-origin-resource-sharingcors&quot;&gt;Cross-origin Resource Sharing(CORS)&lt;/h3&gt;

&lt;p&gt;例如从&lt;code class=&quot;highlighter-rouge&quot;&gt;http://www.a.com/test.html&lt;/code&gt;发起对&lt;code class=&quot;highlighter-rouge&quot;&gt;http://www.b.com/test.php&lt;/code&gt;的请求，请求头中包含&lt;code class=&quot;highlighter-rouge&quot;&gt;origin:http://www.a.com&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;（origin header 可以用于防范CSRF，不像Refer那么容易被伪造或清空，此处的referer怎么改？？？？？😱😱😱😱😱😱😱😱😱😱😱）&lt;/p&gt;

&lt;p&gt;如果www.b.com返回的http Header中包含：&lt;code class=&quot;highlighter-rouge&quot;&gt;Access control allow origin:http://www.a.com&lt;/code&gt;,则表示这个跨域请求被通过。（下图是图糙理不糙啊啊啊&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/SOP/ACAO.png&quot; height=&quot;250&quot; width=&quot;450&quot; /&gt;&lt;/p&gt;

&lt;p&gt;还有很多其他的标准：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Access-Control-Allow-Origin
Access-Control-Allow-Methods
Access-Control-Allow-Headers
Access-Control-Max-Age
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;content-security-policycsp&quot;&gt;Content Security Policy(CSP)&lt;/h3&gt;

&lt;p&gt;由服务器返回一个HTTP头，并在其中描述页面该遵守的安全策略。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X-Content-Security-Policy:allow 'self' *.mydomain.com    // 浏览器将信任来自mydomain.com及其子域名下面的内容
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;CSP的实质为白名单，在浏览器层面做的防护，是和同源策略同一级别，除非浏览器本身出现漏洞，否则不可能从机制上绕过。
CSP只允许被认可的JS块、JS文件、CSS等解析，只允许向指定的域发起请求。&lt;/p&gt;

&lt;p&gt;CSP怎么能有这么多姿势…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://jaq.alibaba.com/community/art/show?spm=a313e.7916646.24000001.49.ZP8rXN&amp;amp;articleid=518&quot;&gt;Content Security Policy 入门教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://paper.seebug.org/423/&quot;&gt;前端防御从入门到弃坑–CSP变迁&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;jsonp只支持get请求&quot;&gt;JSONP(只支持get请求)&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;JSONP(JSON with Padding)&lt;/code&gt;是一个简单高效的跨域方式，可以简单理解为带callback的json。利用&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签没有跨域限制的“漏洞”（历史遗迹啊）来达到与第三方通讯的目的。
参考&lt;a href=&quot;https://www.zhihu.com/question/19966531/answer/13502030&quot;&gt;知乎&lt;/a&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;当需要通讯时，本站脚本创建一个&amp;lt;script&amp;gt;元素，地址指向第三方的API网址，形如:

    &amp;lt;script src=&quot;http://www.example.net/api?param1=1&amp;amp;param2=2&quot;&amp;gt;&amp;lt;/script&amp;gt;

并提供一个回调函数来接收数据（函数名可约定，或通过地址参数传递）。     

第三方产生的响应为json数据的包装（故称之为jsonp，即json padding），形如：     

    callback({&quot;name&quot;:&quot;hax&quot;,&quot;gender&quot;:&quot;Male&quot;})     

这样浏览器会调用callback函数，并传递解析后json对象作为参数。本站脚本可在callback函数里处理所传入的数据。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;JSONP是CSP的克星&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script src=&quot;/path/jsonp?callback=alert(document.domain)//&quot;&amp;gt; &amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;postmessage&quot;&gt;postMessage&lt;/h3&gt;

&lt;p&gt;postMessage允许每一个window（包括当前窗口、弹出窗口、iframe等）对象往其他的窗口发送文本消息，从而实现跨窗口的消息传递，不受同源策略限制。&lt;/p&gt;

&lt;h3 id=&quot;同源攻防&quot;&gt;同源攻防&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.anquanke.com/post/id/86078&quot;&gt;漫谈同源策略攻防&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对URI的解析：&lt;/p&gt;

    &lt;p&gt;在某些浏览器对URI的解释存在漏洞的时候，可以构造相应的攻击连绕过SOP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;设计缺陷绕过SOP：&lt;/p&gt;

    &lt;p&gt;在Java6，7中，如果两个域名解析到相同的IP，则会认为他们同源。假设我们有attacker.com和victim.com,两者都共享主机123.123.123.123。攻击者attacker.com可以在自己控制的域名下上传一个jar文件来访问victim.com的内容。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;访问本地文件的同源策略&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;frame src=&quot;/home/user/dir/2.html&quot;&amp;gt;&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;frame src=&quot;/home/user/2.html&quot;&amp;gt;&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;1.html与2.html视为同源&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特立独行的IE：&lt;/p&gt;

    &lt;p&gt;TrustZones（信任域）：当一个URI被加入到了IE的信任网站区域中时，浏览器会无视同源策略。&lt;/p&gt;

    &lt;p&gt;IE在考虑同源策略时不包括端口， 这意味着不同端口上的应用程序可以读取到比如用户的登陆账户密码/cookie等。&lt;/p&gt;

    &lt;p&gt;通过变更自身的源绕过同源策略：IE 6，7版中网页可以通过document.domain设置自身的来源为任意其他来源&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;防御&quot;&gt;防御&lt;/h3&gt;
&lt;p&gt;最好的防御方式则是设置CORS&lt;/p&gt;

&lt;p&gt;禁止跨域写，引入CSRF令牌，且必须正确的配置同源策略，否则令牌也会被读取。&lt;/p&gt;

&lt;p&gt;禁止跨域读，我们可以通过设置&lt;code class=&quot;highlighter-rouge&quot;&gt;X-Frame-Options&lt;/code&gt;头来禁止该页面被嵌入到恶意页面中&lt;/p&gt;

&lt;p&gt;禁止跨域嵌入，比如&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;script data-original=&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;、 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;img data-original=x&amp;gt;&amp;lt;/img&amp;gt;&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;svg onload=&amp;gt;&lt;/code&gt;，各种字体加载等等。同时，使用CSRF令牌也可以有效避免被跨域嵌入。&lt;/p&gt;

</description>
        <pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E7%9B%B8%E5%85%B3/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/%E9%9D%A2%E8%AF%95_%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E7%9B%B8%E5%85%B3/</guid>
        
        <category>Sec</category>
        
        
      </item>
    
      <item>
        <title>LSTM相关的一些问题</title>
        <description>&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;最近在看深度学习相关的东西，就把一些自己想了很久，网上的答案也不是很详细的东西记录下来，可能会有部分错误，会不断改进哒。&lt;/p&gt;

&lt;h3 id=&quot;rnn-与-lstm-相关基础&quot;&gt;RNN 与 LSTM 相关基础&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;网上看到的RNN的网络图如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM//RNN-shorttermdepdencies.png&quot; height=&quot;280&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是也可以将RNN的网络图画成如下的模式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM//LSTM3-SimpleRNN.png&quot; height=&quot;280&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;是不是很眼熟！对，LSTM只是在RNN的基础上进行了扩展，添加了很多gate来控制之前的记忆，以解决RNN可能引起的梯度弥散与梯度爆炸(这里可以参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25518711&quot;&gt;YJango的循环神经网络——实现LSTM&lt;/a&gt;)的问题。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;传统的LSTM的网络图看上去特别复杂:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM//LSTM3-chain.png&quot; height=&quot;280&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;小圆圈是point-wise的操作，比如向量加法、点乘等&lt;/li&gt;
      &lt;li&gt;小矩形代表一层可学习参数的神经网络（重点啊！！！！！！！！&lt;/li&gt;
      &lt;li&gt;上面的一条直线代表了LSTM的状态state，贯穿所有LSTM单元，gate控制对其添加或删除信息&lt;/li&gt;
      &lt;li&gt;门（gate）是为了控制每次输入多少、遗忘多少、输出多少信息。通过学习和训练，来调节这个gate的值，以达到最好的效果。类似于一个阀门控制水流的多少，具体阀门的松紧即gate的值，需要通过反复学习训练来得到。&lt;/li&gt;
      &lt;li&gt;遗忘们（forget gate）决定上一时刻的单元状态Ct-1有多少保留到当前时刻Ct；输入门（input gate）决定当前时刻网络的输入Xt有多少保留到单元状态Ct；输出门（output gate）来控制单元状态Ct有多少输出到LSTM的当前输出值ht。
  具体可以参考：
  &lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;Understanding LSTM Networks&lt;/a&gt;，
  &lt;a href=&quot;https://zhuanlan.zhihu.com/p/25518711&quot;&gt;YJango的循环神经网络——实现LSTM&lt;/a&gt;
  &lt;a href=&quot;https://www.zybuluo.com/hanbingtao/note/581764&quot;&gt;长短时记忆网络(LSTM)&lt;/a&gt;
因此，很多LSTM想不清楚的问题，可以直接用RNN来类比啦🤗~&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lstm的输入与输出&quot;&gt;LSTM的输入与输出&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;首先还是看下RNN的输入与输出吧(摘自&lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;)：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/charseq.jpeg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;An example RNN with 4-dimensional input and output layers, and a hidden layer of 3 units (neurons). 
This diagram shows the activations in the forward pass when the RNN is fed the characters &quot;hell&quot; as input. 
The output layer contains confidences the RNN assigns for the next character (vocabulary is &quot;h,e,l,o&quot;); 
We want the green numbers to be high and red numbers to be low.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;将”hello”这个单词的每次字母进行One-Hot编码，每输入一个字母预测下一个输出的字母是什么。例如，输入h对应输出e，输入e对应输出l，而输入l则可能对应l或者o。此处对应4维的输入与输出层，一个有着三个神经元的隐藏层。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;batch_size&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;input_size&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;time_steps&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;num_units&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;layer_num&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;class_num&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;再看下这个知乎回答上的这个图,可能会更加清晰一些:
&lt;img src=&quot;/images/posts/2018/03/LSTM/知乎RNN图.jpg&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/41949741/answer/318771336&quot;&gt;作者：Scofield&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;所以，LSTM的输入与输出是怎样的呢？可以完全类比RNN的输入与输出。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/myLSTM.jpg&quot; height=&quot;600&quot; width=&quot;850&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这张图我手工画的，可能有不对的地方，主要参考了&lt;a href=&quot;https://jasdeep06.github.io/posts/Understanding-LSTM-in-Tensorflow-MNIST/&quot;&gt;Understanding LSTM in Tensorflow(MNIST dataset)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;困惑了我最久的是num_units到底是什么，然后&lt;a href=&quot;https://www.zhihu.com/question/41949741/answer/309529532&quot;&gt;知乎&lt;/a&gt;这个回答好详细！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/singleLSTMcell.png&quot; height=&quot;300&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图中四个黄色的框框就是传统的前馈神经网络，而num_units就是这个前馈神经网络里面的隐藏节点啊啊啊啊。&lt;/p&gt;

&lt;h3 id=&quot;关于张量tensor的一些疑惑&quot;&gt;关于张量(tensor)的一些疑惑&lt;/h3&gt;

&lt;p&gt;神经网络的处理单位均为&lt;code class=&quot;highlighter-rouge&quot;&gt;向量&lt;/code&gt;，所以&lt;code class=&quot;highlighter-rouge&quot;&gt;张量&lt;/code&gt;是什么？&lt;/p&gt;

&lt;p&gt;主要参考这篇文章&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25268020&quot;&gt;数学不行还学AI-第4话-图解张量&lt;/a&gt;,写的通俗易懂，我就不摘抄啦噜。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2018/03/LSTM/tensor.jpg&quot; height=&quot;500&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;p&gt;常见的张量有：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3D = 时间序列   (time, frequency, channel)

4D = 图像      (sample_size, width, height, color_depth)

5D = 视频      (sample_size, frames, width, height, color_depth))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;总而言之，张量想要多少维就多少维，就看你的需求与设计啦。&lt;/p&gt;

&lt;h3 id=&quot;暂时就写这么多吧想到了再补充&quot;&gt;暂时就写这么多吧，想到了再补充&lt;/h3&gt;

</description>
        <pubDate>Thu, 01 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/03/LSTM%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/LSTM%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</guid>
        
        <category>AI</category>
        
        
      </item>
    
  </channel>
</rss>
