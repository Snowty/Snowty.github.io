---
layout: post
title: hadoop相关基础
date: 2018-09-18
tags: Sec
---

### 概述
1.  狭义的hadoop：
    ```
    HDFS:分布式存储
    MapReduce:分布式计算
    YARN:资源调度
    ```
    广义hadoop生态圈:
    ```
    Flume进行数据采集
    Spark/MR/Hive等进行数据处理
    HDFS/HBase进行数据存储
    ```
    <img src="/images/posts/2018/09/hadoop//hadoop生态.png" height="280" width="600"> 

2.  HDFS架构：
    <img src="/images/posts/2018/09/hadoop//hdfs架构.png" height="400" width="600">

    `1 个Master（即为NameNode/NN）带N个Slaves（DataNode/DN）`

    1个文件会被拆分成多个Block，例:blocksize 128M

    NN:
    ```
    1)负责客户端请求的响应
    2)负责元数据（文件的名称、副本洗漱、block存放的DN）的管理
    ```
    DN：
    ```
    1）存储用户的文件对应的数据块（Block）
    2) 要定期向NN发送心跳信息，汇报本身及所有的block信息，健康状况
    ```
3.  启动HDFS:`sbin/start-dfs.sh`

    验证是否启动成功：`jps`

    浏览器：`http://localhost:50070`

    停止HDFS:   `sbin/stop-dfs.sh`

4.  HDFS优点：高容错、批处理、适合大数据处理、可部署在廉价机器上
    缺点：延迟大、不适合小文件


5.  YARN架构

    <img src="/images/posts/2018/09/hadoop//yarn架构.png" height="400" width="600">

    `1 RM(Resource Manager)+ N NM(Node Manager)`

    Resource Manager的职责： 一个集群active状态的RM只有一个，负责整个集群的资源管理和调度
    ```
    1） 处理客户端的请求（启动/杀死）
    2） 启动/监控ApplicationMaster（一个作业对应一个AM）
    3） 监控NM
    4） 系统的资源分配和调度
    ```
    NodeManager：整个集群中有N个，负责单个节点的资源管理和使用以及task的运行情况
    ```
    1）定期向RM汇报本节点的资源使用情况和各个Container的运行状态
    2）接收并处理RM的container启停的各种命令
    3）单个节点的资源管理和任务管理
    ```
    ApplicationMaseter：每个应用/作业对应一个，负责应用程序的管理
    ```
    1）数据切分
    2）为应用程序向RM申请资源（container），并分配给内部任务
    3）与NM通信并启停task，task是运行在container中的
    4）task的监控和容错
    ```
    Container：
    ```
    对任务运行情况的描述:CPU、memory、环境变量
    ```

    YARN执行流程：
    ```
    1) 用户向YARN提交作业
    2）RM为该作业分配第一个container（启动AM）
    3) RM会与对应的NM通信，要求NM在这个container上启动应用程序的AM
    4）AM首先向RM注册，然后AM将为各个任务申请资源，并监控运行情况
    5）AM采用轮训的方式通过RPC协议向RM申请和领取资源
    6）AM申请到资源以后，便和相应的NM通信，要求NM启动任务
    7）NM启动我们作业对应的task

    ```
    <img src="/images/posts/2018/09/hadoop//yarn执行流程.png" height="400" width="600">
    启动yarn：`sbin/start-yarn.sh`,`http://localhost:8088`


6.  Hive:构建在hadoop上面的数据仓库，使用hdfs进行数据存储，使用MR进行计算。
        用于离线数据处理，底层的执行引擎有MR、Tez、Spark，支持多种不同的压缩/存储格式,统一的元数据管理（可与SparkSQL等共享数据）
    <img src="/images/posts/2018/09/hadoop//hive架构.png" height="400" width="600">

    基本操作：
    ```
    创建表：create table hive_wordcount(context string);
    加载数据到hive：load data local inpath './hello.txt' into table hive_wordcount;
    统计：select word,count(1) from hive_wordcount lateral view explode(split(context,'\t')) wc as word group by word;
    (lateral view explode():把每行记录按照指定分隔符进行拆解) 
    hive sql 提交执行以后会生成MR作业，并在yarn上运行
    ```

7.  spark：数据处理框架，快：基于内存，DAG执行引擎，基于线程的模型（有线程池）
8.  MR的局限性：
    ```
    1) 代码繁琐
    2）只能够支持map和reduce方法
    3）执行效率低下
    4）不适合迭代多次、交互式、流式的处理
    ```

    架构多样化：
    ```
    1) 批处理（离线）：MapReduce、Hive、Pig
    2）流式处理（实时）：Storm、JStorm
    3）交互式计算：Impala
    ```

9.  Spark与Hadoop对比：
    <img src="/images/posts/2018/09/hadoop//hadoop与spark对比.png" height="400" width="600">
    <img src="/images/posts/2018/09/hadoop//内部对比.png" height="400" width="600">

    MR与Spark对比：存储位置不同（磁盘与内存）
    <img src="/images/posts/2018/09/hadoop//mr与spark.png" height="400" width="600">

    Hadoop+Spark
    <img src="/images/posts/2018/09/hadoop//hadoop+spark.png" height="200" width="600">

