---
layout: post
title: 用户行为日志分析
date: 2018-09-20
tags: 大数据
---

### 前言

慕课网[《以慕课网日志分析为例 进入大数据 Spark SQL 的世界》](https://coding.imooc.com/class/112.html)笔记。

### 日志数据内容
1）访问的系统属性：操纵系统、浏览器等

2）访问特征：点击的url、从哪个url跳转过来（referer）、页面上的停留时间

3）访问信息：session_id、访问ip信息（城市信息）等

### 离线数据处理流程
1）数据采集：

    Flume：将日志从一个地方采集到另一个地方，如web日志到HDFS
    
2）数据清洗：

    脏数据：spark、Hive、MapReduce等，清洗完的数据可以放在HDFS中

3）数据处理：

    按照需求进行相应业务逻辑的统计和分析，spark、Hive、MapReduce等

4）处理结果入库

    结果可以存放到RDBMS、NoSQL

5）数据的可视化展示

    通过图像化展示的方式展现出来：饼图、柱状图、地图、折线图

    ECharts、HUE、Zeppelin

<img src="/images/posts/2018/09/日志分析//离线处理.png" height="350" width="600">

一般的日志处理方式，需要进行分区，如：d，h，m5（每5min）